This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where content has been compressed (code blocks are separated by ⋮---- delimiter).

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Content has been compressed - code blocks are separated by ⋮---- delimiter

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.github/
  ISSUE_TEMPLATE/
    config.yaml
    request_new_features.md
    show_me_the_bug.md
  workflows/
    build-package.yaml
    pre-commit.yaml
    stale.yaml
  PULL_REQUEST_TEMPLATE.md
app/
  agent/
    __init__.py
    base.py
    manus.py
    planning.py
    react.py
    swe.py
    toolcall.py
  flow/
    base.py
    flow_factory.py
    planning.py
  llm/
    cost.py
    inference.py
  mcp/
    __init__.py
    client.py
    README.md
    tool.py
  prompt/
    manus.py
    planning.py
    swe.py
    toolcall.py
  tool/
    search/
      __init__.py
      baidu_search.py
      base.py
      duckduckgo_search.py
      google_search.py
    __init__.py
    aider_tool.py
    ask_human.py
    base.py
    bash.py
    browser_use_tool.py
    code_editor.py
    create_chat_completion.py
    file_saver.py
    planning.py
    python_execute.py
    repo_map.py
    run.py
    str_replace_editor.py
    terminal.py
    terminate.py
    tool_collection.py
    web_search.py
  config.py
  exceptions.py
  logger.py
  schema.py
config/
  config.example.toml
  mcp_config.example.json
examples/
  japan-travel-plan/
    japan_travel_guide_instructions.txt
    japan_travel_handbook_mobile.html
    japan_travel_handbook_print.html
    japan_travel_handbook.html
  mcp_server_example.py
  readme.md
openmanus_server/
  assets/
    claude-desktop-mcp-hammer-icon.svg
  mcp_requirements.txt
  openmanus_client.py
  openmanus_server.py
  README.md
tests/
  mcp/
    test_mcp_integration.py
  tool/
    __init__.py
    simple_test_code_editor.py
    test_aider_tool.py
    test_code_editor.py
    test_diff.py
    test_file.txt
    test_manus_direct.txt
    test_whole.py
  README.md
.gitattributes
.gitignore
.gitmodules
.pre-commit-config.yaml
.repomixignore
ai_agent_improvement_implementation.md
app.py
CODE_OF_CONDUCT.md
improving_ai_agent_capabilities.md
LICENSE
main.py
openmanus_repo_map.md
README_ja.md
README_ko.md
README_zh.md
README.md
requirements.txt
run_flow.py
run_tests.py
setup.py

================================================================
Files
================================================================

================
File: .github/ISSUE_TEMPLATE/config.yaml
================
blank_issues_enabled: false
contact_links:
  - name: "📑 Read online docs"
    about: Find tutorials, use cases, and guides in the OpenManus documentation.

================
File: .github/ISSUE_TEMPLATE/request_new_features.md
================
---
name: "🤔 Request new features"
about: Suggest ideas or features you’d like to see implemented in OpenManus.
title: ''
labels: kind/features
assignees: ''
---

**Feature description**
<!-- Provide a clear and concise description of the proposed feature -->

**Your Feature**
<!-- Explain your idea or implementation process. Optionally, include a Pull Request URL. -->
<!-- Ensure accompanying docs/tests/examples are provided for review. -->

================
File: .github/ISSUE_TEMPLATE/show_me_the_bug.md
================
---
name: "🪲 Show me the Bug"
about: Report a bug encountered while using OpenManus and seek assistance.
title: ''
labels: kind/bug
assignees: ''
---

**Bug description**
<!-- Clearly describe the bug you encountered -->

**Bug solved method**
<!-- If resolved, explain the solution. Optionally, include a Pull Request URL. -->
<!-- If unresolved, provide additional details to aid investigation -->

**Environment information**
<!-- System: e.g., Ubuntu 22.04, Python: e.g., 3.12, OpenManus version: e.g., 0.1.0 -->

- System version:
- Python version:
- OpenManus version or branch:
- Installation method (e.g., `pip install -r requirements.txt` or `pip install -e .`):

**Screenshots or logs**
<!-- Attach screenshots or logs to help diagnose the issue -->

================
File: .github/workflows/build-package.yaml
================
name: Build and upload Python package

on:
  workflow_dispatch:
  release:
    types: [created, published]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install setuptools wheel twine
      - name: Set package version
        run: |
          export VERSION="${GITHUB_REF#refs/tags/v}"
          sed -i "s/version=.*/version=\"${VERSION}\",/" setup.py
      - name: Build and publish
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          python setup.py bdist_wheel sdist
          twine upload dist/*

================
File: .github/workflows/pre-commit.yaml
================
name: Pre-commit checks

on:
  pull_request:
    branches:
      - '**'
  push:
    branches:
      - '**'

jobs:
  pre-commit-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Source Code
        uses: actions/checkout@v4
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install pre-commit and tools
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit black==23.1.0 isort==5.12.0 autoflake==2.0.1
      - name: Run pre-commit hooks
        run: pre-commit run --all-files

================
File: .github/workflows/stale.yaml
================
name: Close inactive issues

on:
  schedule:
    - cron: "5 0 * * *"

jobs:
  close-issues:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    steps:
      - uses: actions/stale@v5
        with:
          days-before-issue-stale: 30
          days-before-issue-close: 14
          stale-issue-label: "inactive"
          stale-issue-message: "This issue has been inactive for 30 days. Please comment if you have updates."
          close-issue-message: "This issue was closed due to 45 days of inactivity. Reopen if still relevant."
          days-before-pr-stale: -1
          days-before-pr-close: -1
          repo-token: ${{ secrets.GITHUB_TOKEN }}

================
File: .github/PULL_REQUEST_TEMPLATE.md
================
**Features**
<!-- Describe the features or bug fixes in this PR. For bug fixes, link to the issue. -->

- Feature 1
- Feature 2

**Feature Docs**
<!-- Provide RFC, tutorial, or use case links for significant updates. Optional for minor changes. -->

**Influence**
<!-- Explain the impact of these changes for reviewer focus. -->

**Result**
<!-- Include screenshots or logs of unit tests or running results. -->

**Other**
<!-- Additional notes about this PR. -->

================
File: app/agent/__init__.py
================
__all__ = [

================
File: app/agent/base.py
================
class BaseAgent(BaseModel, ABC)
⋮----
"""Abstract base class for managing agent state and execution.

    Provides foundational functionality for state transitions, memory management,
    and a step-based execution loop. Subclasses must implement the `step` method.
    """
⋮----
# Core attributes
name: str = Field(..., description="Unique name of the agent")
description: Optional[str] = Field(None, description="Optional agent description")
⋮----
# Prompts
system_prompt: Optional[str] = Field(
next_step_prompt: Optional[str] = Field(
⋮----
# Dependencies
llm: LLM = Field(default_factory=LLM, description="Language model instance")
memory: Memory = Field(default_factory=Memory, description="Agent's memory store")
state: AgentState = Field(
⋮----
# Execution control
max_steps: int = Field(default=10, description="Maximum steps before termination")
current_step: int = Field(default=0, description="Current step in execution")
⋮----
duplicate_threshold: int = Field(default=2, description="Threshold for duplicate messages")
⋮----
class Config
⋮----
arbitrary_types_allowed = True
extra = "allow"  # Allow extra fields for flexibility in subclasses
⋮----
@model_validator(mode="after")
    def initialize_agent(self) -> "BaseAgent"
⋮----
"""Initialize agent with default settings if not provided."""
⋮----
@asynccontextmanager
    async def state_context(self, new_state: AgentState)
⋮----
"""Context manager for safe agent state transitions.

        Args:
            new_state: The state to transition to during the context.

        Yields:
            None: Allows execution within the new state.

        Raises:
            ValueError: If the new_state is invalid.
        """
⋮----
previous_state = self.state
⋮----
self.state = AgentState.ERROR  # Transition to ERROR on failure
⋮----
self.state = previous_state  # Revert to previous state
⋮----
role: ROLE_TYPE,  # type: ignore
⋮----
"""Add a message to the agent's memory.

        Args:
            role: The role of the message sender (user, system, assistant, tool).
            content: The message content.
            **kwargs: Additional arguments (e.g., tool_call_id for tool messages).

        Raises:
            ValueError: If the role is unsupported.
        """
message_map = {
⋮----
msg_factory = message_map[role]
msg = msg_factory(content, **kwargs) if role == "tool" else msg_factory(content)
⋮----
async def run(self, request: Optional[str] = None) -> str
⋮----
"""Execute the agent's main loop asynchronously.

        Args:
            request: Optional initial user request to process.

        Returns:
            A string summarizing the execution results.

        Raises:
            RuntimeError: If the agent is not in IDLE state at start.
        """
⋮----
results: List[str] = []
⋮----
step_result = await self.step()
⋮----
# Check for stuck state
⋮----
@abstractmethod
    async def step(self) -> str
⋮----
"""Execute a single step in the agent's workflow.

        Must be implemented by subclasses to define specific behavior.
        """
⋮----
def handle_stuck_state(self)
⋮----
"""Handle stuck state by adding a prompt to change strategy"""
stuck_prompt = "\
⋮----
def is_stuck(self) -> bool
⋮----
"""Check if the agent is stuck in a loop by detecting duplicate content"""
⋮----
last_message = self.memory.messages[-1]
⋮----
# Count identical content occurrences
duplicate_count = sum(
⋮----
@property
    def messages(self) -> List[Message]
⋮----
"""Retrieve a list of messages from the agent's memory."""
⋮----
@messages.setter
    def messages(self, value: List[Message])
⋮----
"""Set the list of messages in the agent's memory."""

================
File: app/agent/manus.py
================
from app.tool.code_editor import FileEditor  # Using FileEditor from code_editor.py
⋮----
class Manus(ToolCallAgent)
⋮----
"""
    A versatile general-purpose agent that uses planning to solve various tasks.

    This agent extends PlanningAgent with a comprehensive set of tools and capabilities,
    including Python execution, web browsing, file operations, and information retrieval
    to handle a wide range of user requests.
    """
⋮----
name: str = "Manus"
description: str = (
⋮----
system_prompt: str = SYSTEM_PROMPT
next_step_prompt: str = NEXT_STEP_PROMPT
⋮----
max_observe: int = 2000
max_steps: int = 20
⋮----
# Add general-purpose tools to the tool collection
available_tools: ToolCollection = Field(
⋮----
# Track current edit mode
current_edit_mode: str = "diff"  # Default to diff mode
⋮----
async def set_edit_mode(self, mode: str) -> str
⋮----
"""Set the current file editing mode"""
valid_modes = ["whole", "diff", "udiff"]
⋮----
async def _handle_special_tool(self, name: str, result: Any, **kwargs)
⋮----
# Clean up browser tool
⋮----
# Continue with parent class handling

================
File: app/agent/planning.py
================
class PlanningAgent(ToolCallAgent)
⋮----
"""
    An agent that creates and manages plans to solve tasks.

    This agent uses a planning tool to create and manage structured plans,
    and tracks progress through individual steps until task completion.
    """
⋮----
name: str = "planning"
description: str = "An agent that creates and manages plans to solve tasks"
⋮----
system_prompt: str = PLANNING_SYSTEM_PROMPT
next_step_prompt: str = NEXT_STEP_PROMPT
⋮----
available_tools: ToolCollection = Field(
tool_choices: TOOL_CHOICE_TYPE = ToolChoice.AUTO  # type: ignore
special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])
⋮----
tool_calls: List[ToolCall] = Field(default_factory=list)
active_plan_id: Optional[str] = Field(default=None)
⋮----
# Add a dictionary to track the step status for each tool call
step_execution_tracker: Dict[str, Dict] = Field(default_factory=dict)
current_step_index: Optional[int] = None
⋮----
max_steps: int = 20
⋮----
@model_validator(mode="after")
    def initialize_plan_and_verify_tools(self) -> "PlanningAgent"
⋮----
"""Initialize the agent with a default plan ID and validate required tools."""
⋮----
async def think(self) -> bool
⋮----
"""Decide the next action based on plan status."""
prompt = (
⋮----
# Get the current step index before thinking
⋮----
result = await super().think()
⋮----
# After thinking, if we decided to execute a tool and it's not a planning tool or special tool,
# associate it with the current step for tracking
⋮----
latest_tool_call = self.tool_calls[0]  # Get the most recent tool call
⋮----
"status": "pending",  # Will be updated after execution
⋮----
async def act(self) -> str
⋮----
"""Execute a step and track its completion status."""
result = await super().act()
⋮----
# After executing the tool, update the plan status
⋮----
latest_tool_call = self.tool_calls[0]
⋮----
# Update the execution status to completed
⋮----
# Update the plan status if this was a non-planning, non-special tool
⋮----
async def get_plan(self) -> str
⋮----
"""Retrieve the current plan status."""
⋮----
result = await self.available_tools.execute(
⋮----
async def run(self, request: Optional[str] = None) -> str
⋮----
"""Run the agent with an optional initial request."""
⋮----
async def update_plan_status(self, tool_call_id: str) -> None
⋮----
"""
        Update the current plan progress based on completed tool execution.
        Only marks a step as completed if the associated tool has been successfully executed.
        """
⋮----
tracker = self.step_execution_tracker[tool_call_id]
⋮----
step_index = tracker["step_index"]
⋮----
# Mark the step as completed
⋮----
async def _get_current_step_index(self) -> Optional[int]
⋮----
"""
        Parse the current plan to identify the first non-completed step's index.
        Returns None if no active step is found.
        """
⋮----
plan = await self.get_plan()
⋮----
plan_lines = plan.splitlines()
steps_index = -1
⋮----
# Find the index of the "Steps:" line
⋮----
steps_index = i
⋮----
# Find the first non-completed step
⋮----
if "[ ]" in line or "[→]" in line:  # not_started or in_progress
# Mark current step as in_progress
⋮----
return None  # No active step found
⋮----
async def create_initial_plan(self, request: str) -> None
⋮----
"""Create an initial plan based on the request."""
⋮----
messages = [
⋮----
response = await self.llm.ask_tool(
assistant_msg = Message.from_tool_calls(
⋮----
plan_created = False
⋮----
result = await self.execute_tool(tool_call)
⋮----
# Add tool response to memory
tool_msg = Message.tool_message(
⋮----
plan_created = True
⋮----
tool_msg = Message.assistant_message(
⋮----
async def main()
⋮----
# Configure and run the agent
agent = PlanningAgent(available_tools=ToolCollection(PlanningTool(), Terminate()))
result = await agent.run("Help me plan a trip to the moon")

================
File: app/agent/react.py
================
class ReActAgent(BaseAgent, ABC)
⋮----
name: str
description: Optional[str] = None
⋮----
system_prompt: Optional[str] = None
next_step_prompt: Optional[str] = None
⋮----
llm: Optional[LLM] = Field(default_factory=LLM)
memory: Memory = Field(default_factory=Memory)
state: AgentState = AgentState.IDLE
⋮----
max_steps: int = 10
current_step: int = 0
⋮----
@abstractmethod
    async def think(self) -> bool
⋮----
"""Process current state and decide next action"""
⋮----
@abstractmethod
    async def act(self) -> str
⋮----
"""Execute decided actions"""
⋮----
async def step(self) -> str
⋮----
"""Execute a single step: think and act."""
should_act = await self.think()

================
File: app/agent/swe.py
================
class SWEAgent(ToolCallAgent)
⋮----
"""An agent that implements the SWEAgent paradigm for executing code and natural conversations."""
⋮----
name: str = "swe"
description: str = "an autonomous AI programmer that interacts directly with the computer to solve tasks."
⋮----
system_prompt: str = SYSTEM_PROMPT
next_step_prompt: str = NEXT_STEP_TEMPLATE
⋮----
available_tools: ToolCollection = ToolCollection(
special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])
⋮----
max_steps: int = 30
⋮----
bash: Bash = Field(default_factory=Bash)
working_dir: str = "."
⋮----
async def think(self) -> bool
⋮----
"""Process current state and decide next action"""
# Update working directory

================
File: app/agent/toolcall.py
================
TOOL_CALL_REQUIRED = "Tool calls required but none provided"
⋮----
class ToolCallAgent(ReActAgent)
⋮----
"""Base agent class for handling tool/function calls with enhanced abstraction"""
⋮----
name: str = "toolcall"
description: str = "an agent that can execute tool calls."
⋮----
system_prompt: str = SYSTEM_PROMPT
next_step_prompt: str = NEXT_STEP_PROMPT
⋮----
available_tools: ToolCollection = ToolCollection(
tool_choices: TOOL_CHOICE_TYPE = ToolChoice.AUTO  # type: ignore
special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])
⋮----
tool_calls: List[ToolCall] = Field(default_factory=list)
⋮----
# MCP tools that have been registered
mcp_tools: Dict[str, Any] = Field(default_factory=dict)
⋮----
max_steps: int = 30
max_observe: Optional[Union[int, bool]] = None
⋮----
async def think(self) -> bool
⋮----
"""Process current state and decide next actions using tools"""
⋮----
user_msg = Message.user_message(self.next_step_prompt)
⋮----
# Get response with tool options
response = await self.llm.ask_tool(
⋮----
# Log response info
⋮----
# Handle different tool_choices modes
⋮----
# Create and add assistant message
assistant_msg = (
⋮----
return True  # Will be handled in act()
⋮----
# For 'auto' mode, continue with content if no commands but content exists
⋮----
async def act(self) -> str
⋮----
"""Execute tool calls and handle their results"""
⋮----
# Return last message content if no tool calls
⋮----
results = []
⋮----
result = await self.execute_tool(command)
⋮----
result = result[: self.max_observe]
⋮----
# Add tool response to memory
tool_msg = Message.tool_message(
⋮----
async def execute_tool(self, command: ToolCall) -> str
⋮----
"""Execute a single tool call with robust error handling"""
⋮----
name = command.function.name
⋮----
# Parse arguments
args = json.loads(command.function.arguments or "{}")
⋮----
# Execute the tool
⋮----
result = await self.available_tools.execute(name=name, tool_input=args)
⋮----
# Format result for display
observation = (
⋮----
# Handle special tools like `finish`
⋮----
error_msg = f"Error parsing arguments for {name}: Invalid JSON format"
⋮----
error_msg = f"⚠️ Tool '{name}' encountered a problem: {str(e)}"
⋮----
async def initialize(self)
⋮----
"""Initialize the agent, including MCP tools."""
⋮----
# Check if MCP module is available
⋮----
# Initialize MCP tools with agent name
⋮----
# Add MCP tools to available tools
⋮----
# Update next_step_prompt to include MCP tools
⋮----
mcp_tools_desc = "\n\n".join([
⋮----
# Add MCP tools to the prompt
# Simply append MCP tools description to the prompt
⋮----
async def _handle_special_tool(self, name: str, result: Any, **kwargs)
⋮----
"""Handle special tool execution and state changes"""
⋮----
# Clean up MCP tools if terminating
⋮----
# Import mcp_client only if needed
⋮----
# Log that we're shutting down MCP servers
⋮----
# Call stop_servers directly without wrapping in tasks or timeouts
# Let any errors propagate to be handled by the caller
⋮----
# Log but don't re-raise - we want to continue with termination
⋮----
# Set agent state to finished
⋮----
@staticmethod
    def _should_finish_execution(**kwargs) -> bool
⋮----
"""Determine if tool execution should finish the agent"""
⋮----
def _is_special_tool(self, name: str) -> bool
⋮----
"""Check if tool name is in special tools list"""
⋮----
@classmethod
    async def create(cls, **kwargs)
⋮----
"""Create and initialize a new agent."""
agent = cls(**kwargs)

================
File: app/flow/base.py
================
class FlowType(str, Enum)
⋮----
PLANNING = "planning"
⋮----
class BaseFlow(BaseModel, ABC)
⋮----
"""Base class for execution flows supporting multiple agents"""
⋮----
agents: Dict[str, BaseAgent]
tools: Optional[List] = None
primary_agent_key: Optional[str] = None
⋮----
class Config
⋮----
arbitrary_types_allowed = True
⋮----
# Handle different ways of providing agents
⋮----
agents_dict = {"default": agents}
⋮----
agents_dict = {f"agent_{i}": agent for i, agent in enumerate(agents)}
⋮----
agents_dict = agents
⋮----
# If primary agent not specified, use first agent
primary_key = data.get("primary_agent_key")
⋮----
primary_key = next(iter(agents_dict))
⋮----
# Set the agents dictionary
⋮----
# Initialize using BaseModel's init
⋮----
@property
    def primary_agent(self) -> Optional[BaseAgent]
⋮----
"""Get the primary agent for the flow"""
⋮----
def get_agent(self, key: str) -> Optional[BaseAgent]
⋮----
"""Get a specific agent by key"""
agent = self.agents.get(key)
⋮----
def add_agent(self, key: str, agent: BaseAgent) -> None
⋮----
"""Add a new agent to the flow"""
⋮----
@abstractmethod
    async def execute(self, input_text: str) -> str
⋮----
"""Execute the flow with given input"""
⋮----
class PlanStepStatus(str, Enum)
⋮----
"""Enum class defining possible statuses of a plan step"""
⋮----
NOT_STARTED = "not_started"
IN_PROGRESS = "in_progress"
COMPLETED = "completed"
BLOCKED = "blocked"
⋮----
@classmethod
    def get_all_statuses(cls) -> list[str]
⋮----
"""Return a list of all possible step status values"""
⋮----
@classmethod
    def get_active_statuses(cls) -> list[str]
⋮----
"""Return a list of values representing active statuses (not started or in progress)"""
⋮----
@classmethod
    def get_status_marks(cls) -> Dict[str, str]
⋮----
"""Return a mapping of statuses to their marker symbols"""

================
File: app/flow/flow_factory.py
================
class FlowFactory
⋮----
"""Factory for creating different types of flows with support for multiple agents"""
⋮----
flows = {
⋮----
flow_class = flows.get(flow_type)

================
File: app/flow/planning.py
================
class PlanningFlow(BaseFlow)
⋮----
"""A flow that manages planning and execution of tasks using agents."""
⋮----
llm: LLM = Field(default_factory=lambda: LLM())
planning_tool: PlanningTool = Field(default_factory=PlanningTool)
executor_keys: List[str] = Field(default_factory=list)
active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
current_step_index: Optional[int] = None
⋮----
# Set executor keys before super().__init__
⋮----
# Set plan ID if provided
⋮----
# Initialize the planning tool if not provided
⋮----
planning_tool = PlanningTool()
⋮----
# Call parent's init with the processed data
⋮----
# Set executor_keys to all agent keys if not specified
⋮----
def get_executor(self, step_type: Optional[str] = None) -> BaseAgent
⋮----
"""
        Get an appropriate executor agent for the current step.
        Can be extended to select agents based on step type/requirements.
        """
# If step type is provided and matches an agent key, use that agent
⋮----
# Otherwise use the first available executor or fall back to primary agent
⋮----
# Fallback to primary agent
⋮----
async def execute(self, input_text: str) -> str
⋮----
"""Execute the planning flow with agents."""
⋮----
# Create initial plan if input provided
⋮----
# Verify plan was created successfully
⋮----
result = ""
⋮----
# Get current step to execute
⋮----
# Exit if no more steps or plan completed
⋮----
# Execute current step with appropriate agent
step_type = step_info.get("type") if step_info else None
executor = self.get_executor(step_type)
step_result = await self._execute_step(executor, step_info)
⋮----
# Check if agent wants to terminate
⋮----
async def _create_initial_plan(self, request: str) -> None
⋮----
"""Create an initial plan based on the request using the flow's LLM and PlanningTool."""
⋮----
# Create a system message for plan creation
system_message = Message.system_message(
⋮----
# Create a user message with the request
user_message = Message.user_message(
⋮----
# Call LLM with PlanningTool
response = await self.llm.ask_tool(
⋮----
# Process tool calls if present
⋮----
# Parse the arguments
args = tool_call.function.arguments
⋮----
args = json.loads(args)
⋮----
# Ensure plan_id is set correctly and execute the tool
⋮----
# Execute the tool via ToolCollection instead of directly
result = await self.planning_tool.execute(**args)
⋮----
# If execution reached here, create a default plan
⋮----
# Create default plan using the ToolCollection
⋮----
async def _get_current_step_info(self) -> tuple[Optional[int], Optional[dict]]
⋮----
"""
        Parse the current plan to identify the first non-completed step's index and info.
        Returns (None, None) if no active step is found.
        """
⋮----
# Direct access to plan data from planning tool storage
plan_data = self.planning_tool.plans[self.active_plan_id]
steps = plan_data.get("steps", [])
step_statuses = plan_data.get("step_statuses", [])
⋮----
# Find first non-completed step
⋮----
status = PlanStepStatus.NOT_STARTED.value
⋮----
status = step_statuses[i]
⋮----
# Extract step type/category if available
step_info = {"text": step}
⋮----
# Try to extract step type from the text (e.g., [SEARCH] or [CODE])
⋮----
type_match = re.search(r"\[([A-Z_]+)\]", step)
⋮----
# Mark current step as in_progress
⋮----
# Update step status directly if needed
⋮----
return None, None  # No active step found
⋮----
async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str
⋮----
"""Execute the current step with the specified agent using agent.run()."""
# Prepare context for the agent with current plan status
plan_status = await self._get_plan_text()
step_text = step_info.get("text", f"Step {self.current_step_index}")
⋮----
# Create a prompt for the agent to execute the current step
step_prompt = f"""
⋮----
# Use agent.run() to execute the step
⋮----
step_result = await executor.run(step_prompt)
⋮----
# Mark the step as completed after successful execution
⋮----
async def _mark_step_completed(self) -> None
⋮----
"""Mark the current step as completed."""
⋮----
# Mark the step as completed
⋮----
# Update step status directly in planning tool storage
⋮----
# Ensure the step_statuses list is long enough
⋮----
# Update the status
⋮----
async def _get_plan_text(self) -> str
⋮----
"""Get the current plan as formatted text."""
⋮----
result = await self.planning_tool.execute(
⋮----
def _generate_plan_text_from_storage(self) -> str
⋮----
"""Generate plan text directly from storage if the planning tool fails."""
⋮----
title = plan_data.get("title", "Untitled Plan")
⋮----
step_notes = plan_data.get("step_notes", [])
⋮----
# Ensure step_statuses and step_notes match the number of steps
⋮----
# Count steps by status
status_counts = {status: 0 for status in PlanStepStatus.get_all_statuses()}
⋮----
completed = status_counts[PlanStepStatus.COMPLETED.value]
total = len(steps)
progress = (completed / total) * 100 if total > 0 else 0
⋮----
plan_text = f"Plan: {title} (ID: {self.active_plan_id})\n"
⋮----
status_marks = PlanStepStatus.get_status_marks()
⋮----
# Use status marks to indicate step status
status_mark = status_marks.get(
⋮----
async def _finalize_plan(self) -> str
⋮----
"""Finalize the plan and provide a summary using the flow's LLM directly."""
plan_text = await self._get_plan_text()
⋮----
# Create a summary using the flow's LLM directly
⋮----
response = await self.llm.ask(
⋮----
# Fallback to using an agent for the summary
⋮----
agent = self.primary_agent
summary_prompt = f"""
summary = await agent.run(summary_prompt)

================
File: app/llm/cost.py
================
#!/usr/bin/env python
# -*- coding: utf-8 -*-
⋮----
class Cost
⋮----
"""
    Cost class can record various costs during running and evaluation.
    Currently we define the following costs:
        accumulated_cost: the total cost (USD $) of the current LLM.
    """
⋮----
def __init__(self) -> None
⋮----
@property
    def accumulated_cost(self) -> float
⋮----
@accumulated_cost.setter
    def accumulated_cost(self, value: float) -> None
⋮----
@property
    def costs(self) -> list
⋮----
def add_cost(self, value: float) -> None
⋮----
def get(self)
⋮----
"""
        Return the costs in a dictionary.
        """
⋮----
def log(self)
⋮----
"""
        Log the costs.
        """
cost = self.get()
logs = ""

================
File: app/llm/inference.py
================
class LLM
⋮----
_instances: Dict[str, "LLM"] = {}
⋮----
instance = super().__new__(cls)
⋮----
):  # Only initialize if not already initialized
llm_config = llm_config or config.llm
llm_config = llm_config.get(config_name, llm_config["default"])
⋮----
# Get model info if available
⋮----
# Configure litellm
⋮----
# Initialize cost tracker
⋮----
# Initialize completion function
⋮----
def _initialize_completion_function(self)
⋮----
"""Initialize the completion function with retry logic"""
⋮----
def attempt_on_error(retry_state)
⋮----
def wrapper(*args, **kwargs)
⋮----
model_name = self.model
⋮----
model_name = f"azure/{self.model}"
⋮----
# Set default parameters if not provided
⋮----
# Add API credentials if not in kwargs
⋮----
resp = completion(**kwargs)
⋮----
@staticmethod
    def format_messages(messages: List[Union[dict, Message]]) -> List[dict]
⋮----
"""
        Format messages for LLM by converting them to OpenAI message format.

        Args:
            messages: List of messages that can be either dict or Message objects

        Returns:
            List[dict]: List of formatted messages in OpenAI format

        Raises:
            ValueError: If messages are invalid or missing required fields
            TypeError: If unsupported message types are provided
        """
formatted_messages = []
⋮----
# If message is already a dict, ensure it has required fields
⋮----
# If message is a Message object, convert it to dict
⋮----
# Validate all messages have required fields
⋮----
def _calculate_and_track_cost(self, response) -> float
⋮----
"""
        Calculate and track the cost of an LLM API call.

        Args:
            response: The response from litellm

        Returns:
            float: The calculated cost
        """
⋮----
# Use litellm's completion_cost function
cost = completion_cost(completion_response=response)
⋮----
# Add the cost to our tracker
⋮----
def is_local(self) -> bool
⋮----
"""
        Check if the model is running locally.

        Returns:
            bool: True if the model is running locally, False otherwise
        """
⋮----
def do_completion(self, *args, **kwargs) -> Tuple[Any, float, float]
⋮----
"""
        Perform a completion request and track cost.

        Returns:
            Tuple[Any, float, float]: (response, current_cost, accumulated_cost)
        """
response = self._completion(*args, **kwargs)
⋮----
# Calculate and track cost
current_cost = self._calculate_and_track_cost(response)
⋮----
@staticmethod
    def encode_image(image_path: str) -> str
⋮----
"""
        Encode an image to base64.

        Args:
            image_path: Path to the image file

        Returns:
            str: Base64-encoded image
        """
⋮----
"""
        Prepare messages for completion, including multimodal content if needed.

        Args:
            text: Text content
            image_path: Optional path to an image file

        Returns:
            List[dict]: Formatted messages
        """
messages = [{"role": "user", "content": text}]
⋮----
base64_image = self.encode_image(image_path)
⋮----
"""
        Perform a multimodal completion with text and image.

        Args:
            text: Text prompt
            image_path: Path to the image file

        Returns:
            Tuple[Any, float, float]: (response, current_cost, accumulated_cost)
        """
messages = self.prepare_messages(text, image_path=image_path)
⋮----
"""
        Send a prompt to the LLM and get the response.

        Args:
            messages: List of conversation messages
            system_msgs: Optional system messages to prepend
            stream (bool): Whether to stream the response
            temperature (float): Sampling temperature for the response

        Returns:
            str: The generated response

        Raises:
            ValueError: If messages are invalid or response is empty
            Exception: For unexpected errors
        """
⋮----
# Format system and user messages
⋮----
system_msgs = self.format_messages(system_msgs)
messages = system_msgs + self.format_messages(messages)
⋮----
messages = self.format_messages(messages)
⋮----
# For Azure, litellm expects model name in format: azure/<deployment_name>
⋮----
# Non-streaming request
response = await litellm.acompletion(
⋮----
# Calculate and track cost
⋮----
# Streaming request
collected_messages = []
⋮----
chunk_message = chunk.choices[0].delta.content or ""
⋮----
# For streaming responses, cost is calculated on the last chunk
⋮----
print()  # Newline after streaming
full_response = "".join(collected_messages).strip()
⋮----
"""
        Ask LLM using functions/tools and return the response.

        Args:
            messages: List of conversation messages
            system_msgs: Optional system messages to prepend
            timeout: Request timeout in seconds
            tools: List of tools to use
            tool_choice: Tool choice strategy
            temperature: Sampling temperature for the response
            **kwargs: Additional completion arguments

        Returns:
            The model's response

        Raises:
            ValueError: If tools, tool_choice, or messages are invalid
            Exception: For unexpected errors
        """
⋮----
# Validate tool_choice
⋮----
# Format messages
⋮----
# Validate tools if provided
⋮----
# Set up the completion request
⋮----
# Calculate and track cost
⋮----
# Check if response is valid
⋮----
def get_cost(self)
⋮----
"""
        Get the current cost information.

        Returns:
            dict: Dictionary containing accumulated cost and individual costs
        """
⋮----
def log_cost(self)
⋮----
"""
        Log the current cost information.

        Returns:
            str: Formatted string of cost information
        """
⋮----
def get_token_count(self, messages)
⋮----
"""
        Get the token count for a list of messages.

        Args:
            messages: List of messages

        Returns:
            int: Token count
        """
⋮----
def __str__(self)
⋮----
def __repr__(self)
⋮----
# Example usage
⋮----
# Load environment variables if needed
⋮----
# Create LLM instance
llm = LLM()
⋮----
# Test text completion
messages = llm.prepare_messages("Hello, how are you?")
⋮----
# Test multimodal if image path is available
image_path = os.getenv("TEST_IMAGE_PATH")

================
File: app/mcp/__init__.py
================
"""MCP (Model Context Protocol) integration for OpenManus."""

================
File: app/mcp/client.py
================
"""MCP client for connecting to MCP servers."""
⋮----
# Import MCP SDK
⋮----
HAS_MCP_SDK = True
⋮----
HAS_MCP_SDK = False
⋮----
class MCPToolSchema(BaseModel)
⋮----
"""Schema for an MCP tool."""
name: str
description: str
inputSchema: Dict[str, Any]
⋮----
class MCPToolResponse(BaseModel)
⋮----
"""Response from an MCP tool call."""
success: bool
content: Optional[Union[str, Dict[str, Any]]] = None
error: Optional[str] = None
⋮----
@model_validator(mode='after')
    def check_content_or_error(self) -> 'MCPToolResponse'
⋮----
"""Ensure either content or error is provided based on success."""
⋮----
class MCPServer(BaseModel)
⋮----
"""Configuration for an MCP server."""
⋮----
command: str
args: List[str]
env: Dict[str, str] = Field(default_factory=dict)
disabled: bool = False
autoApprove: List[str] = Field(default_factory=list)
agents: List[str] = Field(default_factory=lambda: ["all"])
⋮----
process: Optional[subprocess.Popen] = None
tools: List[MCPToolSchema] = Field(default_factory=list)
client: Optional[Any] = None
⋮----
class Config
⋮----
arbitrary_types_allowed = True
⋮----
class MCPClient
⋮----
"""Client for interacting with MCP servers."""
⋮----
_instance = None
_lock = asyncio.Lock()
⋮----
def __new__(cls)
⋮----
def __init__(self)
⋮----
# Initialization is done in __new__ to ensure it only happens once
⋮----
async def initialize(self, config_path: Optional[str] = None)
⋮----
"""Initialize MCP client from config file."""
⋮----
# Default config paths
⋮----
home_dir = os.path.expanduser("~")
possible_paths = [
⋮----
config_path = path
⋮----
config = json.load(f)
⋮----
# Get auto-approve list with security validation
auto_approve = server_config.get("autoApprove", [])
⋮----
# Security check: Warn about potentially dangerous auto-approved tools
⋮----
dangerous_patterns = [
⋮----
# Get agents list
agents = server_config.get("agents", ["all"])
⋮----
server = MCPServer(
⋮----
# Create MCP session - we don't need to create a session here
# as we'll use stdio_client directly which handles session creation
⋮----
# Start servers
⋮----
async def start_servers(self)
⋮----
"""Start all configured MCP servers."""
⋮----
# Start server process with MCP SDK
env = os.environ.copy()
⋮----
# Create server parameters
params = StdioServerParameters(
⋮----
# Connect to server
⋮----
# Connect using stdio transport
stdio_transport = await self.exit_stack.enter_async_context(
⋮----
# Create session from transport
⋮----
session = await self.exit_stack.enter_async_context(
⋮----
# Initialize session
⋮----
# Get available tools
⋮----
async def stop_servers(self)
⋮----
"""Stop all running MCP servers."""
⋮----
# First, mark as uninitialized to prevent new operations
⋮----
# Store references to servers and clients before clearing them
servers_to_close = list(self.servers.items())
⋮----
# Clear references to servers and clients
⋮----
# Close each server client individually
⋮----
# Try to close the client gracefully
⋮----
# Properly close the exit stack
⋮----
# Create a new exit stack
⋮----
# Log completion
⋮----
async def fetch_server_tools(self, server_name: str) -> List[MCPToolSchema]
⋮----
"""Fetch available tools from an MCP server."""
⋮----
server = self.servers.get(server_name)
⋮----
# Get tools from server
tools_response = await server.client.list_tools()
⋮----
# Log basic info about tools response at debug level
⋮----
# Handle different response formats
tools = []
⋮----
# Check if tools_response is a tuple (client, response) from FastMCP
⋮----
# FastMCP returns (client, response)
⋮----
tool_list = response.tools
⋮----
# Try to access tools from response.result
tool_list = getattr(response, 'result', {}).get('tools', [])
⋮----
# Direct response with tools attribute
tool_list = tools_response.tools
⋮----
# Try to access tools from dictionary
tool_list = getattr(tools_response, 'result', {}).get('tools', [])
⋮----
# Convert to MCPToolSchema
⋮----
# Handle different tool formats
⋮----
# Object with attributes
name = tool.name
description = getattr(tool, 'description', '') or ''
input_schema = getattr(tool, 'input_schema', {}) or {}
⋮----
# Ensure input schema has 'type' field
⋮----
input_schema = {
⋮----
# Dictionary format
name = tool.get('name', '')
description = tool.get('description', '')
input_schema = tool.get('inputSchema', {}) or tool.get('input_schema', {})
⋮----
# Skip invalid tool format
⋮----
"""Call a tool on an MCP server.
        
        Args:
            server_name: Name of the MCP server
            tool_name: Name of the tool to call
            arguments: Arguments to pass to the tool
            
        Returns:
            MCPToolResponse: Response from the tool call with success status and content/error
        """
⋮----
# Call tool directly on the session
⋮----
result = await server.client.call_tool(tool_name, arguments)
⋮----
# Process result
⋮----
# Handle string result (FastMCP often returns strings directly)
⋮----
# Extract text content if available
⋮----
# Return raw content if no text content found
⋮----
error_msg = f"Failed to call tool {tool_name} on MCP server {server_name}: {e}"
⋮----
# Singleton instance
mcp_client = MCPClient()

================
File: app/mcp/README.md
================
# MCP Integration for OpenManus

This module provides integration with the Model Context Protocol (MCP) for OpenManus, allowing you to register custom tools from MCP servers.

## Overview

The MCP integration allows OpenManus to:

1. Connect to MCP servers
2. Discover available tools
3. Register tools with the OpenManus agent
4. Execute tools as part of the agent's workflow

## Configuration

MCP servers are configured in a JSON file. By default, the system looks for configuration in the following locations:

- `~/.config/openmanus/mcp_config.json`
- `~/Library/Application Support/OpenManus/mcp_config.json`
- `config/mcp_config.json`

The configuration file should have the following structure:

```json
{
  "mcpServers": {
    "server-name": {
      "command": "command-to-run-server",
      "args": ["arg1", "arg2"],
      "env": {
        "ENV_VAR1": "value1",
        "ENV_VAR2": "value2"
      },
      "disabled": false,
      "autoApprove": []
    }
  }
}
```

### Configuration Options

- `command`: The command to run the MCP server
- `args`: Arguments to pass to the command
- `env`: Environment variables to set when running the server
- `disabled`: Whether the server is disabled (default: false)
- `autoApprove`: List of tool names that can be auto-approved (default: empty)

## Creating an MCP Server

You can create an MCP server using the MCP SDK. Here's a simple example using FastMCP with lifespan support:

```python
from contextlib import asynccontextmanager
from dataclasses import dataclass
from typing import AsyncIterator

from mcp.server.fastmcp import FastMCP

# Define server context
@dataclass
class AppContext:
    """Context for server operations."""
    request_count: int = 0

@asynccontextmanager
async def app_lifespan(server: FastMCP) -> AsyncIterator[AppContext]:
    """Manage application lifecycle with type-safe context."""
    try:
        # Initialize on startup
        print("Initializing server...")
        context = AppContext()
        yield context
    finally:
        # Cleanup on shutdown
        print(f"Shutting down server. Total requests: {context.request_count}")

# Create a named server with lifespan
app = FastMCP("example-server", lifespan=app_lifespan)

# Define a tool that uses the context
@app.tool()
async def hello_world(ctx, name: str) -> str:
    """Say hello to someone.
    
    Args:
        ctx: Tool context
        name: Name to greet
        
    Returns:
        Greeting message
    """
    # Get lifespan context and increment request count
    app_context = ctx.request_context.lifespan_context
    app_context.request_count += 1
    
    return f"Hello, {name}!"

if __name__ == "__main__":
    app.run(transport="stdio")
```

Save this as `example_server.py` and add it to your MCP configuration:

```json
{
  "mcpServers": {
    "example": {
      "command": "python",
      "args": ["path/to/example_server.py"]
    }
  }
}
```

## Usage

The MCP integration is automatically initialized when the OpenManus agent is created. The agent will connect to all configured MCP servers and register their tools.

You can then use the MCP tools just like any other tool in OpenManus.

### Example: Using MCP Tools in a Prompt

When MCP tools are registered, they are automatically added to the agent's available tools. You can use them in your prompts like this:

```
You can use the calculator_calculate tool to perform calculations.
For example: calculator_calculate(a=5, b=3, operation="add")
```

### Example: Programmatically Using MCP Tools

You can also use MCP tools programmatically:

```python
from app.agent.manus import Manus

# Create and initialize the agent
agent = await Manus.create()

# Use an MCP tool
result = await agent.available_tools.execute(
    name="calculator_calculate",
    tool_input={
        "a": 5,
        "b": 3,
        "operation": "add"
    }
)

print(result)  # Output: Result of 5 add 3 = 8
```

## Advanced Usage

### Auto-Approval of Tools

You can configure certain tools to be auto-approved in the MCP configuration:

```json
{
  "mcpServers": {
    "calculator": {
      "command": "python",
      "args": ["examples/mcp_server_example.py"],
      "disabled": false,
      "autoApprove": ["calculate", "sqrt"]
    }
  }
}
```

Tools listed in the `autoApprove` array will be executed without requiring user confirmation.

### Custom Tool Names

By default, MCP tools are registered with names in the format `{server_name}_{tool_name}`. You can customize this by providing a custom name when creating an MCPTool:

```python
from app.mcp.tool import MCPTool

custom_tool = MCPTool(
    server_name="calculator",
    tool_name="calculate",
    name="my_custom_calculator"
)
```

## Requirements

- MCP SDK (`pip install mcp`)

## Troubleshooting

### Common Issues

1. **MCP SDK not installed**: If you see the error "MCP SDK not installed", make sure you have installed the MCP SDK with `pip install mcp`.

2. **Server not found**: If you see the error "MCP server X not found", check your MCP configuration file to ensure the server is properly configured.

3. **Tool not found**: If you see the error "MCP tool X not found on server Y", make sure the tool is properly defined in your MCP server.

### Debugging

You can enable debug logging to see more detailed information about MCP operations:

```python
import logging
logging.getLogger("app.mcp").setLevel(logging.DEBUG)
```

================
File: app/mcp/tool.py
================
"""MCP tool adapter for OpenManus."""
⋮----
class MCPTool(BaseTool)
⋮----
"""Tool that calls an MCP server tool."""
⋮----
server_name: str = ""
tool_name: str = ""
⋮----
"""Initialize an MCP tool.
        
        Args:
            server_name: Name of the MCP server
            tool_name: Name of the tool on the MCP server
            name: Name of the tool in OpenManus (defaults to server_name.tool_name)
            description: Description of the tool (defaults to the MCP tool description)
            parameters: Parameters schema (defaults to the MCP tool input schema)
        """
⋮----
# Find the tool in the server
server = mcp_client.servers.get(server_name)
⋮----
mcp_tool = next((t for t in server.tools if t.name == tool_name), None)
⋮----
# Use provided values or defaults from MCP tool
# Ensure tool name follows the pattern ^[a-zA-Z0-9_-]{1,64}$
⋮----
# Replace dots with underscores to follow naming pattern
name = f"{server_name}_{tool_name}"
⋮----
# Validate name format
⋮----
# Sanitize name to follow the pattern
name = re.sub(r'[^a-zA-Z0-9_-]', '_', name)[:64]
⋮----
description = description or mcp_tool.description
⋮----
# Ensure parameters have the correct format
⋮----
# Get input schema from MCP tool
input_schema = mcp_tool.inputSchema
⋮----
# Ensure input schema has 'type' field
⋮----
input_schema = {
⋮----
parameters = input_schema
⋮----
# Set server and tool names after initialization
⋮----
async def execute(self, **kwargs) -> ToolResult
⋮----
"""Execute the MCP tool."""
⋮----
response = await mcp_client.call_tool(
⋮----
# Try to parse JSON if the result is a string
⋮----
parsed_result = json.loads(response.content)
⋮----
class MCPToolRegistry
⋮----
"""Registry for MCP tools."""
⋮----
@staticmethod
    async def initialize(agent_name: str = "all") -> Dict[str, MCPTool]
⋮----
"""Initialize MCP tools from servers.
        
        Args:
            agent_name: Name of the agent to initialize tools for. If "all", initialize for all agents.
            
        Returns:
            Dictionary of MCP tools.
        """
⋮----
# Make sure MCP client is initialized
⋮----
tools = {}
⋮----
# Create tools for each server
⋮----
# Check if this server should be available for this agent
# Get agents list from the server config in mcp_config.json
allowed_agents = getattr(server, "agents", ["all"])
⋮----
# Skip if this server is not allowed for this agent
⋮----
tool = MCPTool(

================
File: app/prompt/manus.py
================
SYSTEM_PROMPT = """You are OpenManus, an advanced AI assistant designed to solve a wide range of tasks using various tools and capabilities. You excel at:
⋮----
NEXT_STEP_PROMPT = """You have access to the following tools to accomplish tasks:

================
File: app/prompt/planning.py
================
PLANNING_SYSTEM_PROMPT = """
⋮----
NEXT_STEP_PROMPT = """

================
File: app/prompt/swe.py
================
SYSTEM_PROMPT = """You are OpenManus SWE (Software Engineering) Agent, an autonomous programmer designed to solve software development tasks efficiently and effectively. You work directly in the command line with a special interface that allows you to navigate and edit files.
⋮----
NEXT_STEP_TEMPLATE = """{{observation}}

================
File: app/prompt/toolcall.py
================
SYSTEM_PROMPT = """You are an OpenManus Tool Call Agent, designed to execute various tools to accomplish tasks. Your primary function is to understand user requests, select appropriate tools, and execute them effectively to achieve the desired outcomes.
⋮----
NEXT_STEP_PROMPT = """Based on the current state and progress, determine which tool to use next to advance toward completing the task. Consider:

================
File: app/tool/search/__init__.py
================
__all__ = [

================
File: app/tool/search/baidu_search.py
================
BAIDUSEARCH_AVAILABLE = True
⋮----
BAIDUSEARCH_AVAILABLE = False
⋮----
class BaiduSearchEngine(WebSearchEngine)
⋮----
def perform_search(self, query, num_results=10, *args, **kwargs)
⋮----
"""Baidu search engine."""

================
File: app/tool/search/base.py
================
class WebSearchEngine(object)
⋮----
"""
        Perform a web search and return a list of URLs.

        Args:
            query (str): The search query to submit to the search engine.
            num_results (int, optional): The number of search results to return. Default is 10.
            args: Additional arguments.
            kwargs: Additional keyword arguments.

        Returns:
            List: A list of dict matching the search query.
        """

================
File: app/tool/search/duckduckgo_search.py
================
DUCKDUCKGO_AVAILABLE = True
⋮----
DUCKDUCKGO_AVAILABLE = False
⋮----
class DuckDuckGoSearchEngine(WebSearchEngine)
⋮----
async def perform_search(self, query, num_results=10, *args, **kwargs)
⋮----
"""DuckDuckGo search engine."""

================
File: app/tool/search/google_search.py
================
class GoogleSearchEngine(WebSearchEngine)
⋮----
def perform_search(self, query, num_results=10, *args, **kwargs)
⋮----
"""Google search engine."""

================
File: app/tool/__init__.py
================
__all__ = [

================
File: app/tool/aider_tool.py
================
class AiderTool(BaseTool)
⋮----
"""Tool for using Aider to assist with code-related tasks"""
⋮----
name: str = "aider"
description: str = """Use Aider to assist with code-related tasks.
⋮----
parameters: Dict = {
⋮----
"""Execute Aider with the given parameters"""
⋮----
# Prepare command arguments
cmd = [
⋮----
"--no-check-update",  # Suppress update check prompt
"--no-show-release-notes",  # Suppress release notes
"--yes-always",  # Automatically say yes to confirmations
"--no-fancy-input",  # Disable fancy input (better for non-interactive use)
⋮----
# Set up environment
env = os.environ.copy()
⋮----
# Run Aider as a subprocess
result = subprocess.run(
⋮----
# Extract Aider's response
output = result.stdout
⋮----
# Find the AI's response in the output
ai_response = output.split("AI: ")[-1] if "AI: " in output else output

================
File: app/tool/ask_human.py
================
class AskHuman(BaseTool)
⋮----
"""Add a tool to ask human for help."""
⋮----
name: str = "ask_human"
description: str = "Use this tool to ask human for help."
parameters: str = {
⋮----
async def execute(self, inquire: str) -> str

================
File: app/tool/base.py
================
class BaseTool(ABC, BaseModel)
⋮----
name: str
description: str
parameters: Optional[dict] = None
⋮----
class Config
⋮----
arbitrary_types_allowed = True
⋮----
async def __call__(self, **kwargs) -> Any
⋮----
"""Execute the tool with given parameters."""
⋮----
@abstractmethod
    async def execute(self, **kwargs) -> Any
⋮----
def to_param(self) -> Dict
⋮----
"""Convert tool to function call format."""
⋮----
class ToolResult(BaseModel)
⋮----
"""Represents the result of a tool execution."""
⋮----
output: Any = Field(default=None)
error: Optional[str] = Field(default=None)
system: Optional[str] = Field(default=None)
⋮----
def __bool__(self)
⋮----
def __add__(self, other: "ToolResult")
⋮----
def __str__(self)
⋮----
def replace(self, **kwargs)
⋮----
"""Returns a new ToolResult with the given fields replaced."""
⋮----
class CLIResult(ToolResult)
⋮----
"""A ToolResult that can be rendered as a CLI output."""
⋮----
class ToolFailure(ToolResult)
⋮----
"""A ToolResult that represents a failure."""
⋮----
class AgentAwareTool
⋮----
agent: Optional = None

================
File: app/tool/bash.py
================
_BASH_DESCRIPTION = """Execute a bash command in the terminal.
⋮----
class _BashSession
⋮----
"""A session of a bash shell."""
⋮----
_started: bool
_process: asyncio.subprocess.Process
⋮----
command: str = "/bin/bash"
_output_delay: float = 0.2  # seconds
_timeout: float = 120.0  # seconds
_sentinel: str = "<<exit>>"
⋮----
def __init__(self)
⋮----
async def start(self)
⋮----
def stop(self)
⋮----
"""Terminate the bash shell."""
⋮----
async def run(self, command: str)
⋮----
"""Execute a command in the bash shell."""
⋮----
# we know these are not None because we created the process with PIPEs
⋮----
# send command to the process
⋮----
# read output from the process, until the sentinel is found
⋮----
# if we read directly from stdout/stderr, it will wait forever for
# EOF. use the StreamReader buffer directly instead.
output = (
⋮----
)  # pyright: ignore[reportAttributeAccessIssue]
⋮----
# strip the sentinel and break
output = output[: output.index(self._sentinel)]
⋮----
output = output[:-1]
⋮----
error = (
⋮----
)  # pyright: ignore[reportAttributeAccessIssue]
⋮----
error = error[:-1]
⋮----
# clear the buffers so that the next output can be read correctly
self._process.stdout._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]
self._process.stderr._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]
⋮----
class Bash(BaseTool)
⋮----
"""A tool for executing bash commands"""
⋮----
name: str = "bash"
description: str = _BASH_DESCRIPTION
parameters: dict = {
⋮----
_session: Optional[_BashSession] = None
⋮----
bash = Bash()
rst = asyncio.run(bash.execute("ls -l"))

================
File: app/tool/browser_use_tool.py
================
MAX_LENGTH = 2000
⋮----
_BROWSER_DESCRIPTION = """
⋮----
class BrowserUseTool(BaseTool)
⋮----
name: str = "browser_use"
description: str = _BROWSER_DESCRIPTION
parameters: dict = {
⋮----
lock: asyncio.Lock = Field(default_factory=asyncio.Lock)
browser: Optional[BrowserUseBrowser] = Field(default=None, exclude=True)
context: Optional[BrowserContext] = Field(default=None, exclude=True)
dom_service: Optional[DomService] = Field(default=None, exclude=True)
⋮----
@field_validator("parameters", mode="before")
    def validate_parameters(cls, v: dict, info: ValidationInfo) -> dict
⋮----
async def _ensure_browser_initialized(self) -> BrowserContext
⋮----
"""Ensure browser and context are initialized."""
⋮----
browser_config_kwargs = {"headless": False}
⋮----
# handle proxy settings.
⋮----
browser_attrs = [
⋮----
value = getattr(config.browser_config, attr, None)
⋮----
context_config = BrowserContextConfig()
⋮----
# if there is context config in the config, use it.
⋮----
context_config = config.browser_config.new_context_config
⋮----
"""
        Execute a specified browser action.

        Args:
            action: The browser action to perform
            url: URL for navigation or new tab
            index: Element index for click or input actions
            text: Text for input action
            script: JavaScript code for execution
            scroll_amount: Pixels to scroll for scroll action
            tab_id: Tab ID for switch_tab action
            **kwargs: Additional arguments

        Returns:
            ToolResult with the action's output or error
        """
⋮----
context = await self._ensure_browser_initialized()
⋮----
element = await context.get_dom_element_by_index(index)
⋮----
download_path = await context._click_element_node(element)
output = f"Clicked element at index {index}"
⋮----
screenshot = await context.take_screenshot(full_page=True)
⋮----
html = await context.get_page_html()
truncated = (
⋮----
text = await context.execute_javascript("document.body.innerText")
⋮----
links = await context.execute_javascript(
⋮----
result = await context.execute_javascript(script)
⋮----
direction = "down" if scroll_amount > 0 else "up"
⋮----
async def get_current_state(self) -> ToolResult
⋮----
"""Get the current browser state as a ToolResult."""
⋮----
state = await context.get_state()
state_info = {
⋮----
async def cleanup(self)
⋮----
"""Clean up browser resources."""
⋮----
def __del__(self)
⋮----
"""Ensure cleanup when object is destroyed."""
⋮----
loop = asyncio.new_event_loop()

================
File: app/tool/code_editor.py
================
class EditResult(BaseModel)
⋮----
"""Result of a file edit operation"""
success: bool
message: str
edited_files: List[str] = Field(default_factory=list)
⋮----
class FileEditor(BaseTool)
⋮----
"""Advanced file editing and creation tool with multiple formats for any file type"""
⋮----
name: str = "file_editor"
description: str = """Edit or create any type of file using specialized formats for precise modifications.
⋮----
parameters: Dict = {
⋮----
"""Execute file edits or creation using the specified format or direct content"""
⋮----
# Direct content mode (file saving)
⋮----
# Create directory if needed
directory = os.path.dirname(os.path.abspath(file_path))
⋮----
# Write the file using aiofiles for async I/O
⋮----
# Standard FileEditor functionality
⋮----
result = await self._apply_whole_file_edits(edits)
⋮----
result = await self._apply_udiff_edits(edits)
else:  # default to diff (search/replace blocks)
result = await self._apply_diff_edits(edits)
⋮----
async def _apply_whole_file_edits(self, edits: str) -> EditResult
⋮----
"""Apply whole file edits"""
edited_files = []
errors = []
⋮----
# Extract file blocks using regex
file_blocks = re.findall(r'([^\n]+)\n```(?:\w+)?\n(.*?)```', edits, re.DOTALL)
⋮----
filename = filename.strip()
⋮----
# Create directory if it doesn't exist
⋮----
# Write the file
⋮----
async def _apply_diff_edits(self, edits: str) -> EditResult
⋮----
"""Apply search/replace block edits"""
⋮----
# Extract search/replace blocks
blocks = self._extract_search_replace_blocks(edits)
⋮----
# Check if file exists
⋮----
# Creating a new file
⋮----
# Read existing file
⋮----
content = f.read()
⋮----
# Apply the edit
new_content = self._replace_text(content, search_text, replace_text)
⋮----
# Write the updated content
⋮----
async def _apply_udiff_edits(self, edits: str) -> EditResult
⋮----
"""Apply unified diff edits"""
⋮----
# Extract diff blocks
diff_blocks = re.findall(r'```diff\n(.*?)```', edits, re.DOTALL)
⋮----
# Parse the diff to get filename and changes
⋮----
content = f.read().splitlines()
⋮----
# Apply the diff
new_content = self._apply_diff_changes(content, changes)
⋮----
def _extract_search_replace_blocks(self, text: str) -> List[Tuple[str, str, str]]
⋮----
"""Extract search/replace blocks from text"""
blocks = []
⋮----
# Find all search/replace blocks
pattern = r'([^\n]+)\n```(?:\w+)?\n<<<<<<< SEARCH\n(.*?)=======\n(.*?)>>>>>>> REPLACE\n```'
matches = re.findall(pattern, text, re.DOTALL)
⋮----
def _replace_text(self, content: str, search: str, replace: str) -> str
⋮----
"""Replace search text with replace text in content"""
# Try exact replacement first
⋮----
# Try flexible matching if exact match fails
search_lines = search.splitlines()
content_lines = content.splitlines()
⋮----
# Check if this section matches
match = True
⋮----
match = False
⋮----
# Replace the matching section
new_content = content_lines[:i] + replace.splitlines() + content_lines[i+len(search_lines):]
⋮----
# No match found
⋮----
def _parse_diff(self, diff: str) -> Tuple[str, List[str]]
⋮----
"""Parse a unified diff to extract filename and changes"""
lines = diff.splitlines()
filename = None
changes = []
⋮----
# Extract filename from the diff header
⋮----
old_file = line[4:].strip()
⋮----
new_file = lines[i+1][4:].strip()
filename = new_file if new_file != '/dev/null' else old_file
⋮----
# Extract changes
in_hunk = False
⋮----
in_hunk = True
⋮----
def _apply_diff_changes(self, content: List[str], changes: List[str]) -> List[str]
⋮----
"""Apply diff changes to content"""
result = content.copy()
i = 0
⋮----
# Context line - should match
⋮----
# Find the context line
context_line = change[1:]
⋮----
i = j + 1
⋮----
# Remove line
⋮----
# Find the line to remove
remove_line = change[1:]
⋮----
# Add line

================
File: app/tool/create_chat_completion.py
================
class CreateChatCompletion(BaseTool)
⋮----
name: str = "create_chat_completion"
description: str = (
⋮----
# Type mapping for JSON schema
type_mapping: dict = {
response_type: Optional[Type] = None
required: List[str] = Field(default_factory=lambda: ["response"])
⋮----
def __init__(self, response_type: Optional[Type] = str)
⋮----
"""Initialize with a specific response type."""
⋮----
def _build_parameters(self) -> dict
⋮----
"""Build parameters schema based on response type."""
⋮----
schema = self.response_type.model_json_schema()
⋮----
def _create_type_schema(self, type_hint: Type) -> dict
⋮----
"""Create a JSON schema for the given type."""
origin = get_origin(type_hint)
args = get_args(type_hint)
⋮----
# Handle primitive types
⋮----
# Handle List type
⋮----
item_type = args[0] if args else Any
⋮----
# Handle Dict type
⋮----
value_type = args[1] if len(args) > 1 else Any
⋮----
# Handle Union type
⋮----
def _get_type_info(self, type_hint: Type) -> dict
⋮----
"""Get type information for a single type."""
⋮----
def _create_union_schema(self, types: tuple) -> dict
⋮----
"""Create schema for Union types."""
⋮----
async def execute(self, required: list | None = None, **kwargs) -> Any
⋮----
"""Execute the chat completion with type conversion.

        Args:
            required: List of required field names or None
            **kwargs: Response data

        Returns:
            Converted response based on response_type
        """
required = required or self.required
⋮----
# Handle case when required is a list
⋮----
required_field = required[0]
result = kwargs.get(required_field, "")
⋮----
# Return multiple fields as a dictionary
⋮----
required_field = "response"
⋮----
# Type conversion logic
⋮----
return result  # Assuming result is already in correct format

================
File: app/tool/file_saver.py
================
class FileSaver(BaseTool)
⋮----
name: str = "file_saver"
description: str = """Save content to a local file at a specified path.
parameters: dict = {
⋮----
async def execute(self, content: str, file_path: str, mode: str = "w") -> str
⋮----
"""
        Save content to a file at the specified path.

        Args:
            content (str): The content to save to the file.
            file_path (str): The path where the file should be saved.
            mode (str, optional): The file opening mode. Default is 'w' for write. Use 'a' for append.

        Returns:
            str: A message indicating the result of the operation.
        """
⋮----
# Ensure the directory exists
directory = os.path.dirname(file_path)
⋮----
# Write directly to the file

================
File: app/tool/planning.py
================
# tool/planning.py
⋮----
_PLANNING_TOOL_DESCRIPTION = """
⋮----
class PlanningTool(BaseTool)
⋮----
"""
    A planning tool that allows the agent to create and manage plans for solving complex tasks.
    The tool provides functionality for creating plans, updating plan steps, and tracking progress.
    """
⋮----
name: str = "planning"
description: str = _PLANNING_TOOL_DESCRIPTION
parameters: dict = {
⋮----
plans: dict = {}  # Dictionary to store plans by plan_id
_current_plan_id: Optional[str] = None  # Track the current active plan
⋮----
"""
        Execute the planning tool with the given command and parameters.

        Parameters:
        - command: The operation to perform
        - plan_id: Unique identifier for the plan
        - title: Title for the plan (used with create command)
        - steps: List of steps for the plan (used with create command)
        - step_index: Index of the step to update (used with mark_step command)
        - step_status: Status to set for a step (used with mark_step command)
        - step_notes: Additional notes for a step (used with mark_step command)
        """
⋮----
"""Create a new plan with the given ID, title, and steps."""
⋮----
# Create a new plan with initialized step statuses
plan = {
⋮----
self._current_plan_id = plan_id  # Set as active plan
⋮----
"""Update an existing plan with new title or steps."""
⋮----
plan = self.plans[plan_id]
⋮----
# Preserve existing step statuses for unchanged steps
old_steps = plan["steps"]
old_statuses = plan["step_statuses"]
old_notes = plan["step_notes"]
⋮----
# Create new step statuses and notes
new_statuses = []
new_notes = []
⋮----
# If the step exists at the same position in old steps, preserve status and notes
⋮----
def _list_plans(self) -> ToolResult
⋮----
"""List all available plans."""
⋮----
output = "Available plans:\n"
⋮----
current_marker = " (active)" if plan_id == self._current_plan_id else ""
completed = sum(
total = len(plan["steps"])
progress = f"{completed}/{total} steps completed"
⋮----
def _get_plan(self, plan_id: Optional[str]) -> ToolResult
⋮----
"""Get details of a specific plan."""
⋮----
# If no plan_id is provided, use the current active plan
⋮----
plan_id = self._current_plan_id
⋮----
def _set_active_plan(self, plan_id: Optional[str]) -> ToolResult
⋮----
"""Set a plan as the active plan."""
⋮----
"""Mark a step with a specific status and optional notes."""
⋮----
def _delete_plan(self, plan_id: Optional[str]) -> ToolResult
⋮----
"""Delete a plan."""
⋮----
# If the deleted plan was the active plan, clear the active plan
⋮----
def _format_plan(self, plan: Dict) -> str
⋮----
"""Format a plan for display."""
output = f"Plan: {plan['title']} (ID: {plan['plan_id']})\n"
⋮----
# Calculate progress statistics
total_steps = len(plan["steps"])
completed = sum(1 for status in plan["step_statuses"] if status == "completed")
in_progress = sum(
blocked = sum(1 for status in plan["step_statuses"] if status == "blocked")
not_started = sum(
⋮----
percentage = (completed / total_steps) * 100
⋮----
# Add each step with its status and notes
⋮----
status_symbol = {

================
File: app/tool/python_execute.py
================
class PythonExecute(BaseTool)
⋮----
"""A tool for executing Python code with timeout and safety restrictions."""
⋮----
name: str = "python_execute"
description: str = "Executes Python code string. Note: Only print outputs are visible, function return values are not captured. Use print statements to see results."
parameters: dict = {
⋮----
def _run_code(self, code: str, result_dict: dict, safe_globals: dict) -> None
⋮----
original_stdout = sys.stdout
⋮----
output_buffer = StringIO()
⋮----
"""
        Executes the provided Python code with a timeout.

        Args:
            code (str): The Python code to execute.
            timeout (int): Execution timeout in seconds.

        Returns:
            Dict: Contains 'output' with execution output or error message and 'success' status.
        """
⋮----
result = manager.dict({"observation": "", "success": False})
⋮----
safe_globals = {"__builtins__": __builtins__}
⋮----
safe_globals = {"__builtins__": __builtins__.__dict__.copy()}
proc = multiprocessing.Process(
⋮----
# timeout process

================
File: app/tool/repo_map.py
================
class RepoMapTool(BaseTool)
⋮----
"""Tool for generating and managing repository maps"""
⋮----
name: str = "repo_map"
description: str = "Generate a map of the repository to understand code structure"
⋮----
parameters: Dict = {
⋮----
# Cache for repository maps
_repo_maps: Dict[str, Dict] = {}
⋮----
"""Generate a repository map"""
⋮----
# Normalize path
root_path = os.path.abspath(root_path)
⋮----
# Check if we have a cached map
cache_key = f"{root_path}:{max_files}:{include_patterns}:{exclude_patterns}"
⋮----
cached_map = self._repo_maps[cache_key]
if (datetime.now() - cached_map["timestamp"]).total_seconds() < 300:  # 5 minutes
⋮----
# Generate the map
repo_map = await self._generate_map(
⋮----
# Cache the map
⋮----
"""Generate a map of the repository"""
# Get all files matching the patterns
all_files = self._get_matching_files(root_path, include_patterns, exclude_patterns)
⋮----
# Limit to max_files
⋮----
all_files = self._prioritize_files(all_files, max_files)
⋮----
# Generate the map
repo_map = "# Repository Map\n\n"
⋮----
# Add directory structure
⋮----
# Add file summaries
⋮----
rel_path = os.path.relpath(file_path, root_path)
summary = self._generate_file_summary(file_path)
⋮----
"""Get all files matching the patterns"""
⋮----
matching_files = []
⋮----
file_path = os.path.join(root, file)
⋮----
# Check if file matches include patterns
included = False
⋮----
included = True
⋮----
# Check if file matches exclude patterns
excluded = False
⋮----
excluded = True
⋮----
def _prioritize_files(self, files: List[str], max_files: int) -> List[str]
⋮----
"""Prioritize files to include in the map"""
# Sort files by importance (e.g., README, main files, etc.)
def file_priority(file_path: str) -> int
⋮----
filename = os.path.basename(file_path).lower()
⋮----
sorted_files = sorted(files, key=file_priority)
⋮----
def _generate_directory_structure(self, root_path: str, files: List[str]) -> str
⋮----
"""Generate a directory structure representation"""
structure = "```\n"
⋮----
# Create a tree structure
tree = {}
⋮----
parts = rel_path.split(os.sep)
⋮----
current = tree
⋮----
current = current[part]
⋮----
# Convert tree to string
def print_tree(node, prefix="", is_last=True)
⋮----
result = ""
⋮----
items = list(node.items())
⋮----
is_last_item = i == len(items) - 1
new_prefix = prefix + ("    " if is_last else "│   ")
⋮----
def _generate_file_summary(self, file_path: str) -> str
⋮----
"""Generate a summary of a file"""
⋮----
# Get file extension
ext = os.path.splitext(file_path)[1].lower()
⋮----
# Read file content
⋮----
content = f.read()
⋮----
# Generate summary based on file type
⋮----
def _summarize_code_file(self, content: str, ext: str) -> str
⋮----
"""Summarize a code file"""
lines = content.splitlines()
⋮----
# Extract imports
imports = []
⋮----
import_lines = [line for line in lines if line.strip().startswith(('import ', 'from '))]
imports = import_lines[:5]  # Limit to 5 imports
⋮----
import_lines = [line for line in lines if line.strip().startswith(('import ', 'require('))]
⋮----
# Extract classes and functions
classes = []
functions = []
⋮----
# Limit to 5 classes and 10 functions
classes = classes[:5]
functions = functions[:10]
⋮----
# Generate summary
summary = f"File type: {ext}\n"
⋮----
def _summarize_text_file(self, content: str) -> str
⋮----
"""Summarize a text file"""
⋮----
# Extract headings from markdown
headings = []
⋮----
# Limit to 10 headings
headings = headings[:10]
⋮----
summary = f"File type: Text/Markdown\n"
⋮----
# Include first few lines
⋮----
preview_lines = lines[:5]
⋮----
def _summarize_config_file(self, content: str, ext: str) -> str
⋮----
"""Summarize a configuration file"""
⋮----
summary = f"File type: Configuration ({ext})\n"
⋮----
preview_lines = lines[:10]

================
File: app/tool/run.py
================
"""Utility to run shell commands asynchronously with a timeout."""
⋮----
TRUNCATED_MESSAGE: str = "<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>"
MAX_RESPONSE_LEN: int = 16000
⋮----
def maybe_truncate(content: str, truncate_after: int | None = MAX_RESPONSE_LEN)
⋮----
"""Truncate content and append a notice if content exceeds the specified length."""
⋮----
timeout: float | None = 120.0,  # seconds
⋮----
"""Run a shell command asynchronously with a timeout."""
process = await asyncio.create_subprocess_shell(

================
File: app/tool/str_replace_editor.py
================
Command = Literal[
SNIPPET_LINES: int = 4
⋮----
MAX_RESPONSE_LEN: int = 16000
⋮----
TRUNCATED_MESSAGE: str = "<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>"
⋮----
_STR_REPLACE_EDITOR_DESCRIPTION = """Custom editing tool for viewing, creating and editing files
⋮----
def maybe_truncate(content: str, truncate_after: int | None = MAX_RESPONSE_LEN)
⋮----
"""Truncate content and append a notice if content exceeds the specified length."""
⋮----
class StrReplaceEditor(BaseTool)
⋮----
"""A tool for executing bash commands"""
⋮----
name: str = "str_replace_editor"
description: str = _STR_REPLACE_EDITOR_DESCRIPTION
parameters: dict = {
⋮----
_file_history: list = defaultdict(list)
⋮----
_path = Path(path)
⋮----
result = await self.view(_path, view_range)
⋮----
result = ToolResult(output=f"File created successfully at: {_path}")
⋮----
result = self.str_replace(_path, old_str, new_str)
⋮----
result = self.insert(_path, insert_line, new_str)
⋮----
result = self.undo_edit(_path)
⋮----
def validate_path(self, command: str, path: Path)
⋮----
"""
        Check that the path/command combination is valid.
        """
# Check if its an absolute path
⋮----
suggested_path = Path("") / path
⋮----
# Check if path exists
⋮----
# Check if the path points to a directory
⋮----
async def view(self, path: Path, view_range: list[int] | None = None)
⋮----
"""Implement the view command"""
⋮----
stdout = f"Here's the files and directories up to 2 levels deep in {path}, excluding hidden items:\n{stdout}\n"
⋮----
file_content = self.read_file(path)
init_line = 1
⋮----
file_lines = file_content.split("\n")
n_lines_file = len(file_lines)
⋮----
file_content = "\n".join(file_lines[init_line - 1 :])
⋮----
file_content = "\n".join(file_lines[init_line - 1 : final_line])
⋮----
def str_replace(self, path: Path, old_str: str, new_str: str | None)
⋮----
"""Implement the str_replace command, which replaces old_str with new_str in the file content"""
# Read the file content
file_content = self.read_file(path).expandtabs()
old_str = old_str.expandtabs()
new_str = new_str.expandtabs() if new_str is not None else ""
⋮----
# Check if old_str is unique in the file
occurrences = file_content.count(old_str)
⋮----
file_content_lines = file_content.split("\n")
lines = [
⋮----
# Replace old_str with new_str
new_file_content = file_content.replace(old_str, new_str)
⋮----
# Write the new content to the file
⋮----
# Save the content to history
⋮----
# Create a snippet of the edited section
replacement_line = file_content.split(old_str)[0].count("\n")
start_line = max(0, replacement_line - SNIPPET_LINES)
end_line = replacement_line + SNIPPET_LINES + new_str.count("\n")
snippet = "\n".join(new_file_content.split("\n")[start_line : end_line + 1])
⋮----
# Prepare the success message
success_msg = f"The file {path} has been edited. "
⋮----
def insert(self, path: Path, insert_line: int, new_str: str)
⋮----
"""Implement the insert command, which inserts new_str at the specified line in the file content."""
file_text = self.read_file(path).expandtabs()
new_str = new_str.expandtabs()
file_text_lines = file_text.split("\n")
n_lines_file = len(file_text_lines)
⋮----
new_str_lines = new_str.split("\n")
new_file_text_lines = (
snippet_lines = (
⋮----
new_file_text = "\n".join(new_file_text_lines)
snippet = "\n".join(snippet_lines)
⋮----
def undo_edit(self, path: Path)
⋮----
"""Implement the undo_edit command."""
⋮----
old_text = self._file_history[path].pop()
⋮----
def read_file(self, path: Path)
⋮----
"""Read the content of a file from a given path; raise a ToolError if an error occurs."""
⋮----
def write_file(self, path: Path, file: str)
⋮----
"""Write the content of a file to a given path; raise a ToolError if an error occurs."""
⋮----
"""Generate output for the CLI based on the content of a file."""
file_content = maybe_truncate(file_content)
⋮----
file_content = file_content.expandtabs()
file_content = "\n".join(

================
File: app/tool/terminal.py
================
class Terminal(BaseTool)
⋮----
name: str = "execute_command"
description: str = """Request to execute a CLI command on the system.
parameters: dict = {
process: Optional[asyncio.subprocess.Process] = None
current_path: str = os.getcwd()
lock: asyncio.Lock = asyncio.Lock()
⋮----
async def execute(self, command: str) -> CLIResult
⋮----
"""
        Execute a terminal command asynchronously with persistent context.

        Args:
            command (str): The terminal command to execute.

        Returns:
            str: The output, and error of the command execution.
        """
# Split the command by & to handle multiple commands
commands = [cmd.strip() for cmd in command.split("&") if cmd.strip()]
final_output = CLIResult(output="", error="")
⋮----
sanitized_command = self._sanitize_command(cmd)
⋮----
# Handle 'cd' command internally
⋮----
result = await self._handle_cd_command(sanitized_command)
⋮----
result = CLIResult(
⋮----
result = CLIResult(output="", error=str(e))
⋮----
# Combine outputs
⋮----
# Remove trailing newlines
⋮----
async def execute_in_env(self, env_name: str, command: str) -> CLIResult
⋮----
"""
        Execute a terminal command asynchronously within a specified Conda environment.

        Args:
            env_name (str): The name of the Conda environment.
            command (str): The terminal command to execute within the environment.

        Returns:
            str: The output, and error of the command execution.
        """
sanitized_command = self._sanitize_command(command)
⋮----
# Construct the command to run within the Conda environment
# Using 'conda run -n env_name command' to execute without activating
conda_command = f"conda run -n {shlex.quote(env_name)} {sanitized_command}"
⋮----
async def _handle_cd_command(self, command: str) -> CLIResult
⋮----
"""
        Handle 'cd' commands to change the current path.

        Args:
            command (str): The 'cd' command to process.

        Returns:
            TerminalOutput: The result of the 'cd' command.
        """
⋮----
parts = shlex.split(command)
⋮----
new_path = os.path.expanduser("~")
⋮----
new_path = os.path.expanduser(parts[1])
⋮----
# Handle relative paths
⋮----
new_path = os.path.join(self.current_path, new_path)
⋮----
new_path = os.path.abspath(new_path)
⋮----
@staticmethod
    def _sanitize_command(command: str) -> str
⋮----
"""
        Sanitize the command for safe execution.

        Args:
            command (str): The command to sanitize.

        Returns:
            str: The sanitized command.
        """
# Example sanitization: restrict certain dangerous commands
dangerous_commands = ["rm", "sudo", "shutdown", "reboot"]
⋮----
# If shlex.split fails, try basic string comparison
⋮----
# Additional sanitization logic can be added here
⋮----
async def close(self)
⋮----
"""Close the persistent shell process if it exists."""
⋮----
async def __aenter__(self)
⋮----
"""Enter the asynchronous context manager."""
⋮----
async def __aexit__(self, exc_type, exc_val, exc_tb)
⋮----
"""Exit the asynchronous context manager and close the process."""

================
File: app/tool/terminate.py
================
_TERMINATE_DESCRIPTION = """Terminate the interaction when the request is met OR if the assistant cannot proceed further with the task.
⋮----
class Terminate(BaseTool)
⋮----
name: str = "terminate"
description: str = _TERMINATE_DESCRIPTION
parameters: dict = {
⋮----
async def execute(self, status: str) -> str
⋮----
"""Finish the current execution"""

================
File: app/tool/tool_collection.py
================
"""Collection classes for managing multiple tools."""
⋮----
class ToolCollection
⋮----
"""A collection of defined tools."""
⋮----
def __init__(self, *tools: BaseTool)
⋮----
def __iter__(self)
⋮----
def to_params(self) -> List[Dict[str, Any]]
⋮----
tool = self.tool_map.get(name)
⋮----
result = await tool(**tool_input)
⋮----
async def execute_all(self) -> List[ToolResult]
⋮----
"""Execute all tools in the collection sequentially."""
results = []
⋮----
result = await tool()
⋮----
def get_tool(self, name: str) -> BaseTool
⋮----
def add_tool(self, tool: BaseTool)
⋮----
def add_tools(self, *tools: BaseTool)

================
File: app/tool/web_search.py
================
class WebSearch(BaseTool)
⋮----
name: str = "web_search"
description: str = """Perform a web search and return a list of relevant links.
parameters: dict = {
_search_engine: dict[str, WebSearchEngine] = {
⋮----
async def execute(self, query: str, num_results: int = 10) -> List[str]
⋮----
"""
        Execute a Web search and return a list of URLs.

        Args:
            query (str): The search query to submit to the search engine.
            num_results (int, optional): The number of search results to return. Default is 10.

        Returns:
            List[str]: A list of URLs matching the search query.
        """
# Run the search in a thread pool to prevent blocking
loop = asyncio.get_event_loop()
search_engine = self.get_search_engine()
links = await loop.run_in_executor(
⋮----
def get_search_engine(self) -> WebSearchEngine
⋮----
"""Determines the search engine to use based on the configuration."""
default_engine = self._search_engine.get("google")
⋮----
engine = config.search_config.engine.lower()

================
File: app/config.py
================
def get_project_root() -> Path
⋮----
"""Get the project root directory"""
⋮----
PROJECT_ROOT = get_project_root()
WORKSPACE_ROOT = PROJECT_ROOT / "workspace"
⋮----
class LLMSettings(BaseModel)
⋮----
model: str = Field(..., description="Model name")
base_url: str = Field(..., description="API base URL")
api_key: str = Field(..., description="API key")
max_tokens: int = Field(4096, description="Maximum number of tokens per request")
temperature: float = Field(1.0, description="Sampling temperature")
api_type: str = Field(..., description="AzureOpenai or Openai")
api_version: str = Field(..., description="Azure Openai version if AzureOpenai")
timeout: int = Field(120, description="Request timeout in seconds")
⋮----
class ProxySettings(BaseModel)
⋮----
server: str = Field(None, description="Proxy server address")
username: Optional[str] = Field(None, description="Proxy username")
password: Optional[str] = Field(None, description="Proxy password")
⋮----
class SearchSettings(BaseModel)
⋮----
engine: str = Field(default="Google", description="Search engine the llm to use")
⋮----
class BrowserSettings(BaseModel)
⋮----
headless: bool = Field(False, description="Whether to run browser in headless mode")
disable_security: bool = Field(
extra_chromium_args: List[str] = Field(
chrome_instance_path: Optional[str] = Field(
wss_url: Optional[str] = Field(
cdp_url: Optional[str] = Field(
proxy: Optional[ProxySettings] = Field(
⋮----
class AppConfig(BaseModel)
⋮----
llm: Dict[str, LLMSettings]
browser_config: Optional[BrowserSettings] = Field(
search_config: Optional[SearchSettings] = Field(
⋮----
class Config
⋮----
arbitrary_types_allowed = True
⋮----
class Config
⋮----
_instance = None
_lock = threading.Lock()
_initialized = False
⋮----
def __new__(cls)
⋮----
def __init__(self)
⋮----
@staticmethod
    def _get_config_path() -> Path
⋮----
root = PROJECT_ROOT
config_path = root / "config" / "config.toml"
⋮----
example_path = root / "config" / "config.example.toml"
⋮----
def _load_config(self) -> dict
⋮----
config_path = self._get_config_path()
⋮----
def _load_initial_config(self)
⋮----
raw_config = self._load_config()
base_llm = raw_config.get("llm", {})
llm_overrides = {
⋮----
default_settings = {
⋮----
# handle browser config.
browser_config = raw_config.get("browser", {})
browser_settings = None
⋮----
# handle proxy settings.
proxy_config = browser_config.get("proxy", {})
proxy_settings = None
⋮----
proxy_settings = ProxySettings(
⋮----
# filter valid browser config parameters.
valid_browser_params = {
⋮----
# if there is proxy settings, add it to the parameters.
⋮----
# only create BrowserSettings when there are valid parameters.
⋮----
browser_settings = BrowserSettings(**valid_browser_params)
⋮----
search_config = raw_config.get("search", {})
search_settings = None
⋮----
search_settings = SearchSettings(**search_config)
⋮----
config_dict = {
⋮----
@property
    def llm(self) -> Dict[str, LLMSettings]
⋮----
@property
    def browser_config(self) -> Optional[BrowserSettings]
⋮----
@property
    def search_config(self) -> Optional[SearchSettings]
⋮----
config = Config()

================
File: app/exceptions.py
================
class ToolError(Exception)
⋮----
"""Raised when a tool encounters an error."""
⋮----
def __init__(self, message)

================
File: app/logger.py
================
_print_level = "INFO"
⋮----
def define_log_level(print_level="INFO", logfile_level="DEBUG", name: str = None)
⋮----
"""Adjust the log level to above level"""
⋮----
_print_level = print_level
⋮----
current_date = datetime.now()
formatted_date = current_date.strftime("%Y%m%d%H%M%S")
log_name = (
⋮----
)  # name a log with prefix name
⋮----
log_dir = PROJECT_ROOT / "logs"
⋮----
logger = define_log_level()

================
File: app/schema.py
================
class Role(str, Enum)
⋮----
"""Message role options"""
⋮----
SYSTEM = "system"
USER = "user"
ASSISTANT = "assistant"
TOOL = "tool"
⋮----
ROLE_VALUES = tuple(role.value for role in Role)
ROLE_TYPE = Literal[ROLE_VALUES]  # type: ignore
⋮----
class ToolChoice(str, Enum)
⋮----
"""Tool choice options"""
⋮----
NONE = "none"
AUTO = "auto"
REQUIRED = "required"
⋮----
TOOL_CHOICE_VALUES = tuple(choice.value for choice in ToolChoice)
TOOL_CHOICE_TYPE = Literal[TOOL_CHOICE_VALUES]  # type: ignore
⋮----
class AgentState(str, Enum)
⋮----
"""Agent execution states"""
⋮----
IDLE = "IDLE"
RUNNING = "RUNNING"
FINISHED = "FINISHED"
ERROR = "ERROR"
⋮----
class Function(BaseModel)
⋮----
name: str
arguments: str
⋮----
class ToolCall(BaseModel)
⋮----
"""Represents a tool/function call in a message"""
⋮----
id: str
type: str = "function"
function: Function
⋮----
class Message(BaseModel)
⋮----
"""Represents a chat message in the conversation"""
⋮----
role: ROLE_TYPE = Field(...)  # type: ignore
content: Optional[str] = Field(default=None)
tool_calls: Optional[List[ToolCall]] = Field(default=None)
name: Optional[str] = Field(default=None)
tool_call_id: Optional[str] = Field(default=None)
⋮----
def __add__(self, other) -> List["Message"]
⋮----
"""支持 Message + list 或 Message + Message 的操作"""
⋮----
def __radd__(self, other) -> List["Message"]
⋮----
"""支持 list + Message 的操作"""
⋮----
def to_dict(self) -> dict
⋮----
"""Convert message to dictionary format"""
message = {"role": self.role}
⋮----
@classmethod
    def user_message(cls, content: str) -> "Message"
⋮----
"""Create a user message"""
⋮----
@classmethod
    def system_message(cls, content: str) -> "Message"
⋮----
"""Create a system message"""
⋮----
@classmethod
    def assistant_message(cls, content: Optional[str] = None) -> "Message"
⋮----
"""Create an assistant message"""
⋮----
@classmethod
    def tool_message(cls, content: str, name, tool_call_id: str) -> "Message"
⋮----
"""Create a tool message"""
⋮----
"""Create ToolCallsMessage from raw tool calls.

        Args:
            tool_calls: Raw tool calls from LLM
            content: Optional message content
        """
formatted_calls = [
⋮----
class Memory(BaseModel)
⋮----
messages: List[Message] = Field(default_factory=list)
max_messages: int = Field(default=100)
⋮----
def add_message(self, message: Message) -> None
⋮----
"""Add a message to memory"""
⋮----
# Optional: Implement message limit
⋮----
def add_messages(self, messages: List[Message]) -> None
⋮----
"""Add multiple messages to memory"""
⋮----
def clear(self) -> None
⋮----
"""Clear all messages"""
⋮----
def get_recent_messages(self, n: int) -> List[Message]
⋮----
"""Get n most recent messages"""
⋮----
def to_dict_list(self) -> List[dict]
⋮----
"""Convert messages to list of dicts"""

================
File: config/config.example.toml
================
# Global LLM configuration
[llm]
model = "gpt-4o" #"claude-3-5-sonnet"
base_url = "https://api.openai.com/v1" # "https://api.anthropic.com"
api_key = "sk-..."
max_tokens = 4096
temperature = 0.0
timeout = 120  # Request timeout in seconds

# [llm] #AZURE OPENAI:
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "gpt-4o" # "claude-3-5-sonnet"
base_url = "https://api.openai.com/v1" # "https://api.anthropic.com"
api_key = "sk-..."
max_tokens = 8192
temperature = 0.0

# Optional configuration for specific browser configuration
# [browser]
# Whether to run browser in headless mode (default: false)
#headless = false
# Disable browser security features (default: true)
#disable_security = true
# Extra arguments to pass to the browser
#extra_chromium_args = []
# Path to a Chrome instance to use to connect to your normal browser
# e.g. '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
#chrome_instance_path = ""
# Connect to a browser instance via WebSocket
#wss_url = ""
# Connect to a browser instance via CDP
#cdp_url = ""

# Optional configuration Proxy settings for the browser
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

# Optional configuration Search settings.
# [search]
# Search engine for agent to use. Default is "Google" can be set to "Baidu" or "DuckDuckGo".
#engine = "Google"

================
File: config/mcp_config.example.json
================
{
  "mcpServers": {
    "example-server": {
      "command": "node",
      "args": ["/path/to/mcp-server.js"],
      "env": {
        "API_KEY": "your-api-key-here"
      },
      "disabled": true,
      "autoApprove": [],
      "agents": ["planning"]
    },
    "example-restricted-server": {
      "command": "python",
      "args": ["/path/to/restricted-server.py"],
      "env": {
        "API_KEY": "your-api-key-here"
      },
      "disabled": true,
      "autoApprove": [],
      "agents": ["manus"]
    }
  }
}

================
File: examples/japan-travel-plan/japan_travel_guide_instructions.txt
================
JAPAN TRAVEL HANDBOOK - GUIDE TO VERSIONS

Location: D:/OpenManus/

1. DETAILED DIGITAL VERSION
File: japan_travel_handbook.html
Best for: Desktop/laptop viewing
Features:
- Complete comprehensive guide
- Detailed itinerary
- Full proposal planning section
- All hotel recommendations
- Comprehensive budget breakdown
Usage: Open in web browser for trip planning and detailed reference

2. PRINT-FRIENDLY VERSION
File: japan_travel_handbook_print.html
Best for: Physical reference during travel
Features:
- Condensed essential information
- Optimized for paper printing
- Clear, printer-friendly formatting
- Quick reference tables
Usage: Print and keep in travel documents folder

3. MOBILE-OPTIMIZED VERSION
File: japan_travel_handbook_mobile.html
Best for: On-the-go reference during trip
Features:
- Touch-friendly interface
- Collapsible sections
- Quick access emergency buttons
- Dark mode support
- Responsive design
Usage: Save to phone's browser bookmarks for quick access

RECOMMENDED SETUP:
1. Before Trip:
   - Use detailed version for planning
   - Print the print-friendly version
   - Save mobile version to phone

2. During Trip:
   - Keep printed version with travel documents
   - Use mobile version for daily reference
   - Access detailed version when needed for specific information

3. Emergency Access:
   - Mobile version has quick-access emergency information
   - Keep printed version as backup
   - All emergency numbers and contacts in both versions

Note: All versions contain the same core information but are formatted differently for optimal use in different situations.

IMPORTANT DATES:
- Trip Duration: April 15-23, 2024
- Proposal Day: April 19, 2024
- Key Reservation Deadlines:
  * Flights: Book by January 2024
  * Hotels: Book by February 2024
  * Restaurant Reservations: Book by January 2024
  * JR Pass: Purchase by March 2024

================
File: examples/japan-travel-plan/japan_travel_handbook_mobile.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Japan Travel Guide (Mobile)</title>
    <style>
        * { box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            margin: 0;
            padding: 10px;
            line-height: 1.6;
            font-size: 16px;
        }
        .container {
            max-width: 100%;
            margin: 0 auto;
        }
        h1 { font-size: 1.5em; margin: 10px 0; }
        h2 { font-size: 1.3em; margin: 8px 0; }
        h3 { font-size: 1.1em; margin: 6px 0; }

        /* Mobile-friendly cards */
        .card {
            background: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin: 10px 0;
            padding: 15px;
        }

        /* Collapsible sections */
        .collapsible {
            background: #f8f9fa;
            border: none;
            border-radius: 8px;
            width: 100%;
            padding: 15px;
            text-align: left;
            font-size: 1.1em;
            font-weight: bold;
            cursor: pointer;
            margin: 5px 0;
        }

        .content {
            display: none;
            padding: 10px;
        }

        .active {
            background: #e9ecef;
        }

        /* Mobile-friendly tables */
        .table-wrapper {
            overflow-x: auto;
            margin: 10px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            min-width: 300px;
        }
        th, td {
            padding: 10px;
            border: 1px solid #ddd;
            text-align: left;
        }
        th {
            background: #f8f9fa;
        }

        /* Touch-friendly lists */
        ul, ol {
            padding-left: 20px;
            margin: 10px 0;
        }
        li {
            margin: 8px 0;
            padding: 5px 0;
        }

        /* Emergency info styling */
        .emergency {
            background: #ffe6e6;
            border-left: 4px solid #ff4444;
            padding: 10px;
            margin: 10px 0;
        }

        /* Quick access buttons */
        .quick-access {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 10px 0;
        }
        .quick-btn {
            background: #007bff;
            color: white;
            border: none;
            border-radius: 20px;
            padding: 10px 20px;
            font-size: 0.9em;
            cursor: pointer;
            flex: 1 1 auto;
            text-align: center;
            min-width: 120px;
        }

        /* Dark mode support */
        @media (prefers-color-scheme: dark) {
            body {
                background: #1a1a1a;
                color: #fff;
            }
            .card {
                background: #2d2d2d;
            }
            .collapsible {
                background: #333;
                color: #fff;
            }
            .active {
                background: #404040;
            }
            th {
                background: #333;
            }
            td, th {
                border-color: #404040;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Japan Travel Guide</h1>
        <p><strong>April 15-23, 2024</strong></p>

        <div class="quick-access">
            <button class="quick-btn" onclick="showSection('emergency')">Emergency</button>
            <button class="quick-btn" onclick="showSection('phrases')">Phrases</button>
            <button class="quick-btn" onclick="showSection('transport')">Transport</button>
            <button class="quick-btn" onclick="showSection('proposal')">Proposal</button>
        </div>

        <div class="emergency card" id="emergency">
            <h2>Emergency Contacts</h2>
            <ul>
                <li>🚑 Emergency: 119</li>
                <li>👮 Police: 110</li>
                <li>🏢 US Embassy: +81-3-3224-5000</li>
                <li>ℹ️ Tourist Info: 03-3201-3331</li>
            </ul>
        </div>

        <button class="collapsible">📅 Daily Itinerary</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>Date</th><th>Location</th><th>Activities</th></tr>
                    <tr><td>Apr 15</td><td>Tokyo</td><td>Arrival, Shinjuku</td></tr>
                    <tr><td>Apr 16</td><td>Tokyo</td><td>Meiji, Harajuku, Senso-ji</td></tr>
                    <tr><td>Apr 17</td><td>Tokyo</td><td>Tea Ceremony, Budokan</td></tr>
                    <tr><td>Apr 18</td><td>Kyoto</td><td>Travel, Kinkaku-ji</td></tr>
                    <tr><td>Apr 19</td><td>Kyoto</td><td>Fushimi Inari, Proposal</td></tr>
                    <tr><td>Apr 20</td><td>Nara</td><td>Deer Park, Temples</td></tr>
                    <tr><td>Apr 21</td><td>Tokyo</td><td>Return, Bay Cruise</td></tr>
                </table>
            </div>
        </div>

        <button class="collapsible">🗣️ Essential Phrases</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>English</th><th>Japanese</th></tr>
                    <tr><td>Thank you</td><td>ありがとう</td></tr>
                    <tr><td>Excuse me</td><td>すみません</td></tr>
                    <tr><td>Please</td><td>お願いします</td></tr>
                    <tr><td>Where is...</td><td>...はどこですか</td></tr>
                    <tr><td>Help!</td><td>助けて!</td></tr>
                </table>
            </div>
        </div>

        <button class="collapsible">🚅 Transportation</button>
        <div class="content">
            <div class="card">
                <h3>Key Routes</h3>
                <ul>
                    <li>Tokyo-Kyoto: 2h15m</li>
                    <li>Kyoto-Nara: 45m</li>
                    <li>Last trains: ~midnight</li>
                </ul>
                <p><strong>JR Pass:</strong> Activate April 15</p>
            </div>
        </div>

        <button class="collapsible">💍 Proposal Plan</button>
        <div class="content">
            <div class="card">
                <h3>April 19 Timeline</h3>
                <ul>
                    <li>4:00 PM: Head to Maruyama Park</li>
                    <li>5:30 PM: Arrive at spot</li>
                    <li>7:00 PM: Dinner at Kikunoi Roan</li>
                </ul>
                <p><strong>Backup:</strong> Gion Shirakawa area</p>
            </div>
        </div>

        <button class="collapsible">💰 Budget Tracker</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>Item</th><th>Budget</th></tr>
                    <tr><td>Hotels</td><td>$1500-2000</td></tr>
                    <tr><td>Transport</td><td>$600-800</td></tr>
                    <tr><td>Food</td><td>$800-1000</td></tr>
                    <tr><td>Activities</td><td>$600-800</td></tr>
                    <tr><td>Shopping</td><td>$500-400</td></tr>
                </table>
            </div>
        </div>
    </div>

    <script>
        // Add click handlers for collapsible sections
        var coll = document.getElementsByClassName("collapsible");
        for (var i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }

        // Function to show specific section
        function showSection(id) {
            document.getElementById(id).scrollIntoView({
                behavior: 'smooth'
            });
        }
    </script>
</body>
</html>

================
File: examples/japan-travel-plan/japan_travel_handbook_print.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Japan Travel Handbook (Print Version) - April 15-23, 2024</title>
    <style>
        @media print {
            body {
                font-family: Arial, sans-serif;
                font-size: 11pt;
                line-height: 1.4;
                margin: 0.5in;
            }
            h1 { font-size: 16pt; }
            h2 { font-size: 14pt; }
            h3 { font-size: 12pt; }

            .section {
                margin: 10px 0;
                padding: 5px;
                border: 1px solid #ccc;
                page-break-inside: avoid;
            }
            .no-break {
                page-break-inside: avoid;
            }

            table {
                border-collapse: collapse;
                width: 100%;
                margin: 10px 0;
            }
            td, th {
                border: 1px solid #000;
                padding: 4px;
                font-size: 10pt;
            }
            ul, ol {
                margin: 5px 0;
                padding-left: 20px;
            }
            li {
                margin: 3px 0;
            }
            .page-break {
                page-break-before: always;
            }
        }
        /* Screen styles */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.4;
            margin: 20px;
            max-width: 800px;
            margin: 0 auto;
        }

        .section {
            margin: 15px 0;
            padding: 15px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }

        table {
            border-collapse: collapse;
            width: 100%;
            margin: 10px 0;
        }
        td, th {
            border: 1px solid #000;
            padding: 8px;
        }
        @media screen {
            .page-break {
                margin: 30px 0;
                border-top: 2px dashed #ccc;
            }
        }
    </style>
</head>
<body>
    <h1>Japan Travel Handbook (Print Version)</h1>
    <p><strong>Trip Dates:</strong> April 15-23, 2024</p>

    <div class="section">
        <h2>Emergency Contacts & Important Information</h2>
        <ul>
            <li>Emergency in Japan: 119 (Ambulance/Fire) / 110 (Police)</li>
            <li>US Embassy Tokyo: +81-3-3224-5000</li>
            <li>Tourist Information Hotline: 03-3201-3331</li>
            <li>Your Travel Insurance: [Write number here]</li>
        </ul>
    </div>

    <div class="section">
        <h2>Daily Itinerary Summary</h2>
        <table>
            <tr><th>Date</th><th>Location</th><th>Key Activities</th></tr>
            <tr><td>Apr 15</td><td>Tokyo</td><td>Arrival, Shinjuku area exploration</td></tr>
            <tr><td>Apr 16</td><td>Tokyo</td><td>Meiji Shrine, Harajuku, Senso-ji, Skytree</td></tr>
            <tr><td>Apr 17</td><td>Tokyo</td><td>Tea Ceremony, Budokan, Yanaka Ginza</td></tr>
            <tr><td>Apr 18</td><td>Kyoto</td><td>Travel to Kyoto, Kinkaku-ji, Gion</td></tr>
            <tr><td>Apr 19</td><td>Kyoto</td><td>Fushimi Inari, Arashiyama, Evening Proposal</td></tr>
            <tr><td>Apr 20</td><td>Nara/Kyoto</td><td>Nara Park day trip, deer feeding</td></tr>
            <tr><td>Apr 21</td><td>Tokyo</td><td>Return to Tokyo, bay cruise</td></tr>
        </table>
    </div>

    <div class="page-break"></div>

    <div class="section">
        <h2>Essential Japanese Phrases</h2>
        <table>
            <tr><th>English</th><th>Japanese</th><th>When to Use</th></tr>
            <tr><td>Arigatou gozaimasu</td><td>ありがとうございます</td><td>Thank you (formal)</td></tr>
            <tr><td>Sumimasen</td><td>すみません</td><td>Excuse me/Sorry</td></tr>
            <tr><td>Onegaishimasu</td><td>お願いします</td><td>Please</td></tr>
            <tr><td>Toire wa doko desu ka?</td><td>トイレはどこですか？</td><td>Where is the bathroom?</td></tr>
            <tr><td>Eigo ga hanasemasu ka?</td><td>英語が話せますか？</td><td>Do you speak English?</td></tr>
        </table>
    </div>

    <div class="section">
        <h2>Transportation Notes</h2>
        <ul>
            <li>JR Pass: Activate on April 15</li>
            <li>Tokyo-Kyoto Shinkansen: ~2h15m</li>
            <li>Kyoto-Nara Local Train: ~45m</li>
            <li>Last trains: Usually around midnight</li>
            <li>Keep ¥3000 for unexpected taxi rides</li>
        </ul>
    </div>

    <div class="page-break"></div>

    <div class="section no-break">
        <h2>Proposal Day Timeline (April 19)</h2>
        <table>
            <tr><th>Time</th><th>Activity</th><th>Notes</th></tr>
            <tr><td>4:00 PM</td><td>Head to Maruyama Park</td><td>Check weather first</td></tr>
            <tr><td>4:30 PM</td><td>Tea house visit</td><td>Light refreshments</td></tr>
            <tr><td>5:15 PM</td><td>Park walk begins</td><td>Head to weeping cherry tree</td></tr>
            <tr><td>5:30 PM</td><td>Arrive at spot</td><td>Find quiet area</td></tr>
            <tr><td>7:00 PM</td><td>Dinner reservation</td><td>Kikunoi Roan</td></tr>
        </table>
        <p><strong>Backup Location:</strong> Gion Shirakawa area (in case of rain)</p>
    </div>

    <div class="section">
        <h2>Quick Reference Budget</h2>
        <table>
            <tr><th>Item</th><th>Budget (USD)</th><th>Notes</th></tr>
            <tr><td>Hotels</td><td>1500-2000</td><td>Pre-booked</td></tr>
            <tr><td>Transport</td><td>600-800</td><td>Including JR Pass</td></tr>
            <tr><td>Food</td><td>800-1000</td><td>~$60/person/day</td></tr>
            <tr><td>Activities</td><td>600-800</td><td>Including tea ceremony</td></tr>
            <tr><td>Shopping</td><td>500-400</td><td>Souvenirs/gifts</td></tr>
        </table>
    </div>
</body>
</html>

================
File: examples/japan-travel-plan/japan_travel_handbook.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Japan Travel Handbook - April 15-23, 2024</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; }
        .container { max-width: 1000px; margin: 0 auto; }
        h1, h2, h3 { color: #333; }
        .day-item { background: #f9f9f9; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .important-note { background: #ffe6e6; padding: 10px; border-radius: 5px; }
        .phrase-table { width: 100%; border-collapse: collapse; }
        .phrase-table td, .phrase-table th { border: 1px solid #ddd; padding: 8px; }
        .proposal-spot { background: #e6ffe6; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .flight-info { background: #e6f3ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .checklist { background: #fff3e6; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .hotels { background: #e6e6ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .proposal-plan { background: #ffe6ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .checkbox-list li { list-style-type: none; margin-bottom: 8px; }
        .checkbox-list li:before { content: "☐ "; }
        .warning { color: #ff4444; }
    </style>
</head>
<body>
    <div class="container">
        [Previous content remains the same...]

        <div class="proposal-plan">
            <h2>🌸 Proposal Planning Guide 🌸</h2>

            <h3>Ring Security & Transport</h3>
            <ul>
                <li><strong>Carrying the Ring:</strong>
                    <ul>
                        <li>Always keep the ring in your carry-on luggage, never in checked bags</li>
                        <li>Use a discrete, non-branded box or case</li>
                        <li>Consider travel insurance that covers jewelry</li>
                        <li>Keep receipt/appraisal documentation separate from the ring</li>
                    </ul>
                </li>
                <li><strong>Airport Security Tips:</strong>
                    <ul>
                        <li>No need to declare the ring unless value exceeds ¥1,000,000 (~$6,700)</li>
                        <li>If asked, simply state it's "personal jewelry"</li>
                        <li>Consider requesting private screening to maintain surprise</li>
                        <li>Keep ring in original box until through security, then transfer to more discrete case</li>
                    </ul>
                </li>
            </ul>

            <h3>Proposal Location Details - Maruyama Park</h3>
            <ul>
                <li><strong>Best Timing:</strong>
                    <ul>
                        <li>Date: April 19 (Day 5)</li>
                        <li>Time: 5:30 PM (30 minutes before sunset)</li>
                        <li>Park closes at 8:00 PM in April</li>
                    </ul>
                </li>
                <li><strong>Specific Spot Recommendations:</strong>
                    <ul>
                        <li>Primary Location: Near the famous weeping cherry tree
                            <br>- Less crowded in early evening
                            <br>- Beautiful illumination starts at dusk
                            <br>- Iconic Kyoto backdrop
                        </li>
                        <li>Backup Location: Gion Shirakawa area
                            <br>- Atmospheric stone-paved street
                            <br>- Traditional buildings and cherry trees
                            <br>- Beautiful in light rain
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>Proposal Day Planning</h3>
            <ul>
                <li><strong>Morning Preparation:</strong>
                    <ul>
                        <li>Confirm weather forecast</li>
                        <li>Transfer ring to secure pocket/bag</li>
                        <li>Have backup indoor location details ready</li>
                    </ul>
                </li>
                <li><strong>Suggested Timeline:</strong>
                    <ul>
                        <li>4:00 PM: Start heading to Maruyama Park area</li>
                        <li>4:30 PM: Light refreshments at nearby tea house</li>
                        <li>5:15 PM: Begin walk through park</li>
                        <li>5:30 PM: Arrive at proposal spot</li>
                        <li>6:00 PM: Sunset and illumination begins</li>
                        <li>7:00 PM: Celebratory dinner reservation</li>
                    </ul>
                </li>
            </ul>

            <h3>Celebration Dinner Options</h3>
            <ul>
                <li><strong>Traditional Japanese:</strong> Kikunoi Roan
                    <br>- Intimate 2-star Michelin restaurant
                    <br>- Advance reservation required (3 months)
                    <br>- Price: ¥15,000-20,000 per person
                </li>
                <li><strong>Modern Fusion:</strong> The Sodoh
                    <br>- Beautiful garden views
                    <br>- Western-style seating available
                    <br>- Price: ¥12,000-15,000 per person
                </li>
            </ul>

            <div class="warning">
                <h3>Important Notes:</h3>
                <ul>
                    <li>Keep proposal plans in separate notes from shared itinerary</li>
                    <li>Have a backup plan in case of rain (indoor locations listed above)</li>
                    <li>Consider hiring a local photographer to capture the moment</li>
                    <li>Save restaurant staff contact info in case of timing changes</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>

================
File: examples/mcp_server_example.py
================
#!/usr/bin/env python3
"""
Example MCP server for OpenManus.

This server provides a simple calculator tool that can perform basic arithmetic operations.
"""
⋮----
# Configure logging
⋮----
logger = logging.getLogger("mcp-calculator")
⋮----
# Define calculator context
⋮----
@dataclass
class CalculatorContext
⋮----
"""Context for calculator operations."""
operations_count: int = 0
⋮----
@asynccontextmanager
async def calculator_lifespan(server: FastMCP) -> AsyncIterator[CalculatorContext]
⋮----
"""Manage calculator lifecycle with type-safe context."""
⋮----
# Initialize on startup
⋮----
context = CalculatorContext()
⋮----
# Cleanup on shutdown
⋮----
# Create a named server with lifespan
calculator = FastMCP("calculator", lifespan=calculator_lifespan)
⋮----
# Define calculator tool
⋮----
@calculator.tool()
def calculate(ctx: Context, a: float, b: float, operation: Literal["add", "subtract", "multiply", "divide"]) -> str
⋮----
"""Perform a calculation on two numbers.

    Args:
        ctx: Tool context
        a: First number
        b: Second number
        operation: Operation to perform (add, subtract, multiply, divide)

    Returns:
        Result of the calculation
    """
⋮----
# Get lifespan context and increment operations count
calc_context = ctx.request_context.lifespan_context
⋮----
result = None
⋮----
result = a + b
⋮----
result = a - b
⋮----
result = a * b
⋮----
result = a / b
⋮----
# Define square root tool
⋮----
@calculator.tool()
def sqrt(ctx: Context, number: float) -> str
⋮----
"""Calculate the square root of a number.

    Args:
        ctx: Tool context
        number: Number to calculate square root of

    Returns:
        Square root of the number
    """
⋮----
result = number ** 0.5

================
File: examples/readme.md
================
# Examples

We put some examples in the `examples` directory. All the examples use the same prompt
as [Manus](https://manus.im/?utm_source=ai-bot.cn).

The Model we use is `claude3.5`.

## Japan Travel Plan
**Prompt**：
```
I need a 7-day Japan itinerary for April 15-23 from Seattle, with a $2500-5000 budget for my fiancée and me. We love historical sites, hidden gems, and Japanese culture (kendo, tea ceremonies, Zen meditation). We want to see Nara's deer and explore cities on foot. I plan to propose during this trip and need a special location recommendation. Please provide a detailed itinerary and a simple HTML travel handbook with maps, attraction descriptions, essential Japanese phrases, and travel tips we can reference throughout our journey.
```
**preview**：
![alt text](./pictures/japan-travel-plan-1.png)

![alt text](./pictures/japan-travel-plan-2.png)

================
File: openmanus_server/assets/claude-desktop-mcp-hammer-icon.svg
================
<svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M31.4175 14L22.985 5.51002C20.7329 3.26243 17.6811 2.00012 14.4993 2.00012C11.3176 2.00012 8.26581 3.26243 6.01372 5.51002L6.00247 5.52127L4.28122 7.30002C4.10292 7.49163 4.00685 7.74552 4.01364 8.00717C4.02043 8.26883 4.12954 8.51739 4.31754 8.6995C4.50554 8.88161 4.75745 8.98276 5.01919 8.98122C5.28092 8.97968 5.53163 8.87558 5.71747 8.69127L7.43372 6.91877C8.12421 6.22842 8.91217 5.64303 9.77247 5.18127L15.585 11L3.58497 23C3.39921 23.1857 3.25185 23.4062 3.15131 23.6489C3.05077 23.8916 2.99902 24.1517 2.99902 24.4144C2.99902 24.6771 3.05077 24.9372 3.15131 25.1799C3.25185 25.4225 3.39921 25.643 3.58497 25.8288L6.17122 28.415C6.35694 28.6008 6.57744 28.7481 6.82012 28.8487C7.06281 28.9492 7.32291 29.001 7.5856 29.001C7.84828 29.001 8.10839 28.9492 8.35107 28.8487C8.59375 28.7481 8.81425 28.6008 8.99997 28.415L21 16.415L22.7925 18.2075L25 20.4125C25.1857 20.5983 25.4062 20.7456 25.6489 20.8462C25.8916 20.9467 26.1517 20.9985 26.4143 20.9985C26.677 20.9985 26.9371 20.9467 27.1798 20.8462C27.4225 20.7456 27.643 20.5983 27.8287 20.4125L31.415 16.8263C31.7897 16.4516 32.0005 15.9436 32.0009 15.4137C32.0014 14.8838 31.7915 14.3753 31.4175 14ZM7.58497 27L4.99997 24.4138L13.5 15.9138L16.085 18.5L7.58497 27ZM20.2925 14.29L17.5 17.0838L14.9137 14.5L17.7075 11.7063C17.8004 11.6134 17.8742 11.5031 17.9245 11.3817C17.9749 11.2603 18.0008 11.1302 18.0008 10.9988C18.0008 10.8673 17.9749 10.7372 17.9245 10.6158C17.8742 10.4944 17.8004 10.3841 17.7075 10.2913L11.79 4.37502C13.4996 3.89351 15.3067 3.87606 17.0253 4.32445C18.744 4.77284 20.3122 5.67089 21.5687 6.92627L27.0962 12.49L23.5 16.0825L21.7075 14.29C21.6146 14.197 21.5043 14.1233 21.3829 14.073C21.2615 14.0226 21.1314 13.9967 21 13.9967C20.8686 13.9967 20.7384 14.0226 20.617 14.073C20.4956 14.1233 20.3853 14.197 20.2925 14.29ZM26.4175 18.9975L24.9175 17.4975L28.5 13.9063L30 15.4063L26.4175 18.9975Z" fill="#343330"/>
</svg>

================
File: openmanus_server/mcp_requirements.txt
================
# Core dependencies
mcp
httpx>=0.27.0
tomli>=2.0.0

================
File: openmanus_server/openmanus_client.py
================
# Initialize colorama
def init_colorama()
⋮----
# Load config
def load_config()
⋮----
config_path = Path(__file__).parent.parent / "config" / "config.toml"
⋮----
# Load environment variables (as fallback)
⋮----
class OpenManusClient
⋮----
def __init__(self)
⋮----
# Load configuration
⋮----
# Initialize session and client objects
⋮----
# Initialize AsyncOpenAI client with config
api_key = self.config["llm"]["api_key"] or os.getenv("OPENAI_API_KEY")
⋮----
async def connect_to_server(self, server_script_path: str = None)
⋮----
"""Connect to the openmanus MCP server"""
# Use provided path or default from config
script_path = server_script_path or self.config["server"]["default_script"]
⋮----
server_params = StdioServerParameters(
⋮----
stdio_transport = await self.exit_stack.enter_async_context(
⋮----
# List available tools
response = await self.session.list_tools()
tools = response.tools
⋮----
async def chat_loop(self)
⋮----
"""Run an interactive chat loop for testing tools"""
⋮----
query = input(Fore.BLUE + "🔍 Query: ").strip()
⋮----
response = await self.process_query(query)
⋮----
async def cleanup(self)
⋮----
"""Clean up resources"""
⋮----
await self.openai_client.close()  # Close the OpenAI client
⋮----
async def process_query(self, query: str) -> str
⋮----
"""Process a query using LLM and available tools"""
# Add a system message to set the context for the model
messages = [
⋮----
available_tools = [
# Initial LLM API call
response = await self.openai_client.chat.completions.create(
⋮----
# Process response and handle tool calls
final_text = []
⋮----
message = response.choices[0].message
⋮----
# Add assistant's message to conversation
⋮----
# If no tool calls, we're done
⋮----
# Handle tool calls
⋮----
tool_name = tool_call.function.name
tool_args = tool_call.function.arguments
⋮----
# Convert tool_args from string to dictionary if necessary
⋮----
tool_args = ast.literal_eval(tool_args)
⋮----
tool_args = {}
⋮----
# Ensure tool_args is a dictionary
⋮----
# Execute tool call
⋮----
result = await self.session.call_tool(tool_name, tool_args)
⋮----
# final_text.append(f"Result: {result.content}")
⋮----
# Add tool result to messages
⋮----
# Get next response from LLM
⋮----
async def main()
⋮----
server_script = sys.argv[1]
⋮----
server_script = "./openmanus_server/openmanus_server.py"
⋮----
client = OpenManusClient()

================
File: openmanus_server/openmanus_server.py
================
# Add current directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
⋮----
# Configure logging
⋮----
logger = logging.getLogger("mcp-server")
⋮----
# Import OpenManus tools
⋮----
# Initialize FastMCP server
openmanus = FastMCP("openmanus")
⋮----
# Initialize tool instances
browser_tool = BrowserUseTool()
google_search_tool = GoogleSearch()
python_execute_tool = PythonExecute()
file_saver_tool = FileSaver()
terminate_tool = Terminate()
⋮----
# Browser tool
⋮----
"""Execute various browser operations.

    Args:
        action: The browser operation to execute, possible values include:
            - navigate: Navigate to specified URL
            - click: Click on an element on the page
            - input_text: Input text into a text field
            - screenshot: Take a screenshot of the current page
            - get_html: Get HTML of the current page
            - get_text: Get text content of the current page
            - execute_js: Execute JavaScript code
            - scroll: Scroll the page
            - switch_tab: Switch to specified tab
            - new_tab: Open new tab
            - close_tab: Close current tab
            - refresh: Refresh current page
        url: URL for 'navigate' or 'new_tab' operations
        index: Element index for 'click' or 'input_text' operations
        text: Text for 'input_text' operation
        script: JavaScript code for 'execute_js' operation
        scroll_amount: Scroll pixels for 'scroll' operation (positive for down, negative for up)
        tab_id: Tab ID for 'switch_tab' operation
    """
⋮----
result = await browser_tool.execute(
⋮----
@openmanus.tool()
async def get_browser_state() -> str
⋮----
"""Get current browser state, including URL, title, tabs and interactive elements."""
⋮----
result = await browser_tool.get_current_state()
⋮----
# Google search tool
⋮----
@openmanus.tool()
async def google_search(query: str, num_results: int = 10) -> str
⋮----
"""Execute Google search and return list of relevant links.

    Args:
        query: Search query
        num_results: Number of results to return (default is 10)
    """
⋮----
results = await google_search_tool.execute(query=query, num_results=num_results)
⋮----
# Python execution tool
⋮----
@openmanus.tool()
async def python_execute(code: str, timeout: int = 5) -> str
⋮----
"""Execute Python code and return results.

    Args:
        code: Python code to execute
        timeout: Execution timeout in seconds
    """
⋮----
result = await python_execute_tool.execute(code=code, timeout=timeout)
⋮----
# File saver tool
⋮----
@openmanus.tool()
async def file_saver(content: str, file_path: str, mode: str = "w") -> str
⋮----
"""Save content to local file.

    Args:
        content: Content to save
        file_path: File path
        mode: File open mode (default is 'w')
    """
⋮----
result = await file_saver_tool.execute(
⋮----
# Terminate tool
⋮----
@openmanus.tool()
async def terminate(status: str) -> str
⋮----
"""Terminate program execution.

    Args:
        status: Termination status, can be 'success' or 'failure'
    """
⋮----
result = await terminate_tool.execute(status=status)
⋮----
# Clean up resources
async def cleanup()
⋮----
"""Clean up all tool resources"""
⋮----
# Register cleanup function
⋮----
def parse_args()
⋮----
"""Parse command line arguments"""
parser = argparse.ArgumentParser(description="OpenManus MCP Server")
⋮----
args = parse_args()

================
File: openmanus_server/README.md
================
# OpenManus-server 🤖

This project provides a server based on [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) that exposes **OpenManus** tool functionalities as standardized APIs.

## ✨ Features

This MCP server provides access to the following OpenManus tools:

1. **Browser Automation** 🌐 - Navigate webpages, click elements, input text, and more
2. **Google Search** 🔍 - Execute searches and retrieve result links
3. **Python Code Execution** 🐍 - Run Python code in a secure environment
4. **File Saving** 💾 - Save content to local files
5. **Termination Control** 🛑 - Control program execution flow

## 🚀 Installation

### Prerequisites

- Python 3.10+
- OpenManus project dependencies

### Installation Steps

1. First, install the OpenManus project:

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

2. Install dependencies:

```bash
# Using uv (recommended)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
source .venv/bin/activate  # Unix/macOS
# or .venv\Scripts\activate  # Windows
uv pip install -r requirements.txt
```

3. Install MCP dependencies:

```bash
uv pip install -r openmanus_server/mcp_requirements.txt
```

## Demo display
https://github.com/user-attachments/assets/177b1f50-422f-4c2e-ab7d-1f3d7ff27679

## 📖 Usage

### 1. Testing your server with Claude for Desktop 🖥️

> ⚠️ **Note**: Claude for Desktop is not yet available on Linux. Linux users can build an MCP client that connects to the server we just built.

#### Step 1: Installation Check ✅
First, make sure you have Claude for Desktop installed. [You can install the latest version here](https://claude.ai/download). If you already have Claude for Desktop, **make sure it's updated to the latest version**.

#### Step 2: Configuration Setup ⚙️
We'll need to configure Claude for Desktop for this server you want to use. To do this, open your Claude for Desktop App configuration at `~/Library/Application Support/Claude/claude_desktop_config.json` in a text editor. Make sure to create the file if it doesn't exist.

```bash
vim ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

#### Step 3: Server Configuration 🔧
You'll then add your servers in the `mcpServers` key. The MCP UI elements will only show up in Claude for Desktop if at least one server is properly configured.

In this case, we'll add our single Openmanus server like so:
```json
{
    "mcpServers": {
        "openmanus": {
            "command": "/ABSOLUTE/PATH/TO/PARENT/FOLDER/uv",
            "args": [
                "--directory",
                "/ABSOLUTE/PATH/TO/OpenManus/openmanus_server",
                "run",
                "openmanus_server.py"
            ]
        }
    }
}
```

> 💡 **Tip**: You may need to put the full path to the uv executable in the command field. You can get this by running:
> - MacOS/Linux: `which uv`
> - Windows: `where uv`

#### Step 4: Understanding the Configuration 📝
This tells Claude for Desktop:
1. There's an MCP server named "openmanus" 🔌
2. To launch it by running `uv --directory /ABSOLUTE/PATH/TO/OpenManus/openmanus_server run openmanus_server.py` 🚀

#### Step 5: Activation 🔄
Save the file, and restart Claude for Desktop.

#### Step 6: Verification ✨
Let's make sure Claude for Desktop is picking up the six tools we've exposed in our `openmanus` server. You can do this by looking for the hammer icon ![hammer icon](./assets/claude-desktop-mcp-hammer-icon.svg)
![tools_in_claude](./assets/1.jpg)

After clicking on the hammer icon, you should see tools listed:
![alvaliable_tools_list](./assets/2.png)

#### Ready to Test! 🎉
**Now, you can test the openmanus server in Claude for Desktop**:
* 🔍 Try to find the recent news about Manus AI agent, and write a post for me!



### 💻 2. Testing with simple Client Example

Check out `openmanus_client.py` to test the openmanus server using the MCP client.

#### Demo display
https://github.com/user-attachments/assets/aeacd93d-9bec-46d1-831b-20e898c7507b
```
python openmanus_server/openmanus_client.py
```


## 🔒 Security Considerations

- When using in production, ensure proper authentication and authorization mechanisms are in place
- The Python execution tool has timeout limits to prevent long-running code

## 📄 License

Same license as the OpenManus project

================
File: tests/mcp/test_mcp_integration.py
================
"""Tests for MCP integration."""
⋮----
def async_test(coro)
⋮----
"""Decorator for async test methods."""
def wrapper(*args, **kwargs)
⋮----
loop = asyncio.get_event_loop()
⋮----
class TestMCPClient(unittest.TestCase)
⋮----
"""Test the MCP client."""
⋮----
def setUp(self)
⋮----
"""Set up the test."""
# Reset the singleton instance
⋮----
@async_test
@patch('app.mcp.client.HAS_MCP_SDK', True)
    async def test_initialize(self)
⋮----
"""Test initializing the MCP client."""
# Create a temporary config file
⋮----
config_path = f.name
⋮----
# Mock the start_servers method to do nothing
⋮----
# Initialize the client
⋮----
# Check that the server was added
⋮----
server = self.client.servers["test-server"]
⋮----
# Check that the server was started
⋮----
# Clean up
⋮----
@async_test
@patch('app.mcp.client.HAS_MCP_SDK', True)
    async def test_call_tool(self)
⋮----
"""Test calling a tool."""
# Create a mock server
server = MCPServer(
⋮----
# Mock the call_tool method
⋮----
# Add the server to the client
⋮----
# Call the tool
result = await self.client.call_tool("test-server", "test-tool", {"arg": "value"})
⋮----
# Check the result
⋮----
# Check that the tool was called
⋮----
@async_test
@patch('app.mcp.client.HAS_MCP_SDK', True)
    async def test_call_tool_error(self)
⋮----
"""Test calling a tool that returns an error."""
⋮----
# Create a mock error response
error_response = MagicMock()
⋮----
class TestMCPTool(unittest.TestCase)
⋮----
"""Test the MCP tool."""
⋮----
@patch('app.mcp.tool.HAS_MCP_SDK', True)
@patch('app.mcp.tool.mcp_client')
    def test_init(self, mock_client)
⋮----
"""Test initializing an MCP tool."""
⋮----
# Create a mock tool schema
tool_schema = MCPToolSchema(
⋮----
# Add the tool to the server
⋮----
# Create the tool
tool = MCPTool(
⋮----
# Check the tool
⋮----
@async_test
@patch('app.mcp.tool.HAS_MCP_SDK', True)
@patch('app.mcp.tool.mcp_client')
    async def test_execute(self, mock_client)
⋮----
"""Test executing an MCP tool."""
⋮----
# Execute the tool
result = await tool.execute(arg="value")
⋮----
@async_test
@patch('app.mcp.tool.HAS_MCP_SDK', True)
@patch('app.mcp.tool.mcp_client')
    async def test_execute_error(self, mock_client)
⋮----
"""Test executing an MCP tool that returns an error."""

================
File: tests/tool/__init__.py
================
"""Tests for the tool module."""

================
File: tests/tool/simple_test_code_editor.py
================
# Get the current directory (tests/tool)
TEST_DIR = os.path.dirname(os.path.abspath(__file__))
⋮----
async def test_diff_format()
⋮----
"""Test the diff format functionality of CodeEditor"""
⋮----
# Test diff format
test_diff_path = os.path.join(TEST_DIR, 'test_diff.py')
⋮----
# First, ensure the file exists with the content we expect
⋮----
result = await CodeEditor().execute(
⋮----
# Read the file to verify
⋮----
content = f.read()

================
File: tests/tool/test_aider_tool.py
================
async def test_aider_tool()
⋮----
"""Test the Aider tool with a simple prompt."""
⋮----
# Create an instance of the AiderTool
aider_tool = AiderTool()
⋮----
# Define a simple prompt
prompt = "Write a simple Python function to calculate the factorial of a number"
⋮----
# Execute the tool
⋮----
result = await aider_tool.execute(prompt=prompt)
⋮----
# Print the result
⋮----
success = asyncio.run(test_aider_tool())

================
File: tests/tool/test_code_editor.py
================
# Get the current directory (tests/tool)
TEST_DIR = os.path.dirname(os.path.abspath(__file__))
⋮----
async def test_code_editor_directly()
⋮----
"""Test the CodeEditor tool directly"""
⋮----
# Test direct content saving in append mode
test_file_path = os.path.join(TEST_DIR, 'test_file.txt')
result = await CodeEditor().execute(
⋮----
# Test whole file format
test_whole_path = os.path.join(TEST_DIR, 'test_whole.py')
⋮----
# Test diff format
test_diff_path = os.path.join(TEST_DIR, 'test_diff.py')
⋮----
async def test_manus_agent()
⋮----
"""Test the Manus agent with CodeEditor replacing FileSaver"""
⋮----
# Create a Manus agent
agent = await Manus.create()
⋮----
# Test direct content saving with CodeEditor through Manus agent
test_manus_path = os.path.join(TEST_DIR, 'test_manus_direct.txt')
result = await agent.available_tools.execute(
⋮----
# Test appending with CodeEditor through Manus agent
⋮----
# Read the file to verify
⋮----
content = f.read()
⋮----
# Verify FileSaver is not available
⋮----
test_file_saver_path = os.path.join(TEST_DIR, 'test_file_saver.txt')
⋮----
# Run both tests

================
File: tests/tool/test_diff.py
================
# Original content
⋮----
def hello()

================
File: tests/tool/test_file.txt
================
Appended content

================
File: tests/tool/test_manus_direct.txt
================
This is a test file created with Manus agent using CodeEditor in direct content mode
This line was appended

================
File: tests/tool/test_whole.py
================


================
File: tests/README.md
================
# OpenManus Tests

This directory contains tests for the OpenManus project.

## Running Tests

To run all tests:

```bash
python -m unittest discover -s tests
```

To run a specific test file:

```bash
python -m unittest tests/mcp/test_mcp_integration.py
```

To run a specific test case:

```bash
python -m unittest tests.mcp.test_mcp_integration.TestMCPClient
```

To run a specific test method:

```bash
python -m unittest tests.mcp.test_mcp_integration.TestMCPClient.test_initialize
```

## Test Structure

- `tests/mcp/`: Tests for the MCP (Model Context Protocol) integration
  - `test_mcp_integration.py`: Tests for the MCP client and tools

## Writing Tests

When writing tests for OpenManus, follow these guidelines:

1. Use the `unittest` framework
2. Use descriptive test method names that explain what is being tested
3. Use the `setUp` and `tearDown` methods to set up and clean up test fixtures
4. Use mocks to isolate the code being tested from external dependencies
5. Test both success and error cases
6. Add docstrings to test classes and methods to explain what is being tested

### Example

```python
import unittest
from unittest.mock import patch

class TestExample(unittest.TestCase):
    """Test example functionality."""

    def setUp(self):
        """Set up the test."""
        # Set up test fixtures

    def tearDown(self):
        """Clean up after the test."""
        # Clean up test fixtures

    @patch('module.dependency')
    def test_example(self, mock_dependency):
        """Test example functionality."""
        # Arrange
        mock_dependency.return_value = "mocked value"
        
        # Act
        result = function_under_test()
        
        # Assert
        self.assertEqual(result, "expected value")

================
File: .gitattributes
================
# HTML code is incorrectly calculated into statistics, so ignore them
*.html linguist-detectable=false
# Auto detect text files and perform LF normalization
* text=auto eol=lf
# Ensure shell scripts use LF (Linux style) line endings on Windows
*.sh text eol=lf
# Treat specific binary files as binary and prevent line ending conversion
*.png binary
*.jpg binary
*.gif binary
*.ico binary
*.jpeg binary
*.mp3 binary
*.zip binary
*.bin binary
# Preserve original line endings for specific document files
*.doc text eol=crlf
*.docx text eol=crlf
*.pdf binary
# Ensure source code and script files use LF line endings
*.py text eol=lf
*.js text eol=lf
*.html text eol=lf
*.css text eol=lf
# Specify custom diff driver for specific file types
*.md diff=markdown
*.json diff=json
*.mp4 filter=lfs diff=lfs merge=lfs -text
*.mov filter=lfs diff=lfs merge=lfs -text
*.webm filter=lfs diff=lfs merge=lfs -text

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# PyPI configuration file
.pypirc

# Logs
logs/

# Data
data/

# Workspace
workspace/
config/config.toml
config/mcp_config.json
.aider*
project/*

================
File: .gitmodules
================
[submodule "aider"]
	path = aider
	url = https://github.com/Aider-AI/aider
[submodule "cline"]
	path = cline
	url = https://github.com/cline/cline
[submodule "repomix"]
	path = repomix
	url = https://github.com/yamadashy/repomix

================
File: .pre-commit-config.yaml
================
repos:
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files

  - repo: https://github.com/PyCQA/autoflake
    rev: v2.0.1
    hooks:
      - id: autoflake
        args: [
          --remove-all-unused-imports,
          --ignore-init-module-imports,
          --expand-star-imports,
          --remove-duplicate-keys,
          --remove-unused-variables,
          --recursive,
          --in-place,
          --exclude=__init__.py,
        ]
        files: \.py$

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: [
          "--profile", "black",
          "--filter-files",
          "--lines-after-imports=2",
        ]

================
File: .repomixignore
================
# Ignore submodules that have been removed
aider/
cline/
repomix/

================
File: ai_agent_improvement_implementation.md
================
# AI Agent Improvement Implementation Guide

Based on my research, here's a practical implementation guide with code examples to help improve AI agent capabilities:

## 1. Implementing Chain-of-Thought Reasoning

Chain-of-thought reasoning helps AI agents break down complex problems into manageable steps. Here's how to implement it:

```python
# Example of implementing chain-of-thought reasoning in a prompt
def chain_of_thought_prompt(question):
    prompt = f"""
    Question: {question}
    
    Let's think through this step by step:
    1. First, I'll identify the key elements of the problem.
    2. Next, I'll determine what information is needed to solve it.
    3. Then, I'll apply relevant methods or formulas.
    4. Finally, I'll verify my solution makes sense.
    
    Step 1: The key elements are...
    """
    return prompt

# Example usage
complex_question = "If a train travels at 60 mph for 2 hours then at 30 mph for 1 hour, what is the average speed?"
reasoning_prompt = chain_of_thought_prompt(complex_question)
```

## 2. Building Tool Selection Frameworks

Effective tool selection is crucial for AI agents. Here's a framework for implementing intelligent tool selection:

```python
class ToolSelectionFramework:
    def __init__(self):
        self.tools = {
            "calculator": {
                "description": "Performs mathematical calculations",
                "keywords": ["calculate", "math", "computation", "number"],
                "function": self.calculator_tool
            },
            "web_search": {
                "description": "Searches the web for information",
                "keywords": ["search", "find", "lookup", "information"],
                "function": self.web_search_tool
            },
            "code_executor": {
                "description": "Executes code in various languages",
                "keywords": ["code", "execute", "run", "program"],
                "function": self.code_execution_tool
            }
        }
        
    def select_tool(self, query):
        """Select the most appropriate tool based on the query"""
        scores = {}
        for tool_name, tool_info in self.tools.items():
            score = 0
            # Check for keyword matches
            for keyword in tool_info["keywords"]:
                if keyword.lower() in query.lower():
                    score += 1
            scores[tool_name] = score
        
        # Get the tool with the highest score
        best_tool = max(scores.items(), key=lambda x: x[1])
        if best_tool[1] > 0:
            return best_tool[0]
        else:
            return None
    
    # Tool implementations
    def calculator_tool(self, input_data):
        # Implementation of calculator functionality
        pass
    
    def web_search_tool(self, query):
        # Implementation of web search functionality
        pass
    
    def code_execution_tool(self, code):
        # Implementation of code execution functionality
        pass
```

## 3. Implementing Self-Monitoring and Evaluation

Self-monitoring helps AI agents detect errors and improve performance:

```python
class SelfMonitoringAgent:
    def __init__(self):
        self.confidence_threshold = 0.7
        self.error_patterns = [
            "I'm not sure",
            "I don't know",
            "I'm uncertain",
            "It's unclear"
        ]
        self.performance_metrics = {
            "accuracy": [],
            "response_time": [],
            "user_satisfaction": []
        }
    
    def evaluate_response(self, response, ground_truth=None):
        """Evaluate the quality of a response"""
        # Check for error patterns
        contains_uncertainty = any(pattern in response for pattern in self.error_patterns)
        
        # Calculate confidence score (simplified example)
        confidence_score = 0.9 if not contains_uncertainty else 0.5
        
        # Record metrics
        if ground_truth:
            accuracy = 1.0 if response == ground_truth else 0.0
            self.performance_metrics["accuracy"].append(accuracy)
        
        # Determine if verification is needed
        needs_verification = confidence_score < self.confidence_threshold
        
        return {
            "confidence": confidence_score,
            "needs_verification": needs_verification,
            "contains_uncertainty": contains_uncertainty
        }
    
    def improve_from_feedback(self, feedback, response):
        """Learn from feedback to improve future responses"""
        # Implementation of learning mechanism
        pass
```

## 4. Implementing Knowledge Integration

Effective knowledge integration helps AI agents combine information from multiple sources:

```python
class KnowledgeIntegrator:
    def __init__(self):
        self.knowledge_base = {}
        self.source_reliability = {
            "academic_paper": 0.9,
            "news_article": 0.7,
            "blog_post": 0.5,
            "social_media": 0.3
        }
    
    def add_information(self, topic, information, source_type):
        """Add new information to the knowledge base"""
        reliability = self.source_reliability.get(source_type, 0.5)
        
        if topic not in self.knowledge_base:
            self.knowledge_base[topic] = []
        
        self.knowledge_base[topic].append({
            "information": information,
            "reliability": reliability,
            "source_type": source_type,
            "timestamp": time.time()
        })
    
    def get_integrated_knowledge(self, topic):
        """Retrieve integrated knowledge on a topic"""
        if topic not in self.knowledge_base:
            return "No information available on this topic."
        
        # Sort by reliability
        sorted_info = sorted(
            self.knowledge_base[topic], 
            key=lambda x: x["reliability"], 
            reverse=True
        )
        
        # Integrate information, prioritizing more reliable sources
        integrated_info = sorted_info[0]["information"]
        
        # Add supplementary information from other sources
        for info in sorted_info[1:]:
            # Check if this information adds something new
            if not self._is_redundant(integrated_info, info["information"]):
                integrated_info += f"\n\nAdditionally: {info['information']}"
        
        return integrated_info
    
    def _is_redundant(self, existing_info, new_info):
        """Check if new information is redundant with existing information"""
        # Simplified implementation
        return new_info in existing_info
```

## 5. Implementing Tool Chaining for Complex Tasks

Tool chaining allows AI agents to solve complex problems by combining multiple tools:

```python
class ToolChain:
    def __init__(self, available_tools):
        self.available_tools = available_tools
        self.execution_history = []
    
    def plan_execution(self, task):
        """Create a plan for executing a complex task"""
        # This would typically involve task decomposition
        # Simplified example:
        if "data analysis" in task.lower():
            return [
                {"tool": "data_loader", "params": {"source": "extract_from_task(task)"}},
                {"tool": "data_processor", "params": {"operations": ["clean", "normalize"]}},
                {"tool": "data_analyzer", "params": {"method": "statistical"}},
                {"tool": "visualizer", "params": {"type": "determine_from_data"}}
            ]
        elif "web research" in task.lower():
            return [
                {"tool": "web_search", "params": {"query": "extract_keywords(task)"}},
                {"tool": "content_extractor", "params": {"depth": "medium"}},
                {"tool": "information_synthesizer", "params": {}}
            ]
        else:
            # Default simple plan
            return [{"tool": "general_solver", "params": {"task": task}}]
    
    def execute_chain(self, task):
        """Execute a chain of tools to complete a task"""
        plan = self.plan_execution(task)
        results = []
        
        for step in plan:
            tool_name = step["tool"]
            params = step["params"]
            
            if tool_name in self.available_tools:
                tool = self.available_tools[tool_name]
                try:
                    result = tool(**params)
                    results.append(result)
                    
                    # Record execution
                    self.execution_history.append({
                        "tool": tool_name,
                        "params": params,
                        "status": "success",
                        "result": result
                    })
                    
                    # Some tools might modify the plan
                    if hasattr(tool, "modify_plan"):
                        plan = tool.modify_plan(plan, result)
                        
                except Exception as e:
                    self.execution_history.append({
                        "tool": tool_name,
                        "params": params,
                        "status": "error",
                        "error": str(e)
                    })
                    # Implement error recovery here
            else:
                self.execution_history.append({
                    "tool": tool_name,
                    "status": "unavailable"
                })
        
        return results
```

## 6. Implementing Feedback Integration Systems

Feedback integration helps AI agents learn from user interactions:

```python
class FeedbackSystem:
    def __init__(self):
        self.feedback_database = []
        self.improvement_areas = {
            "accuracy": [],
            "clarity": [],
            "relevance": [],
            "completeness": []
        }
    
    def collect_feedback(self, response_id, feedback_text, rating):
        """Collect and store user feedback"""
        feedback_entry = {
            "response_id": response_id,
            "feedback_text": feedback_text,
            "rating": rating,
            "timestamp": time.time()
        }
        
        self.feedback_database.append(feedback_entry)
        self.analyze_feedback(feedback_entry)
        
        return True
    
    def analyze_feedback(self, feedback):
        """Analyze feedback to identify improvement areas"""
        # Simplified sentiment analysis
        negative_terms = {
            "accuracy": ["incorrect", "wrong", "inaccurate", "error"],
            "clarity": ["confusing", "unclear", "difficult to understand", "complex"],
            "relevance": ["irrelevant", "off-topic", "unrelated", "not what I asked"],
            "completeness": ["incomplete", "missing", "partial", "not enough"]
        }
        
        feedback_text = feedback["feedback_text"].lower()
        
        for area, terms in negative_terms.items():
            if any(term in feedback_text for term in terms):
                self.improvement_areas[area].append(feedback)
    
    def get_improvement_suggestions(self):
        """Generate improvement suggestions based on feedback"""
        suggestions = {}
        
        for area, feedback_items in self.improvement_areas.items():
            if feedback_items:
                # Count occurrences to prioritize
                count = len(feedback_items)
                recent = any(time.time() - item["timestamp"] < 86400 for item in feedback_items)
                
                priority = "high" if (count > 5 or recent) else "medium" if count > 2 else "low"
                
                suggestions[area] = {
                    "priority": priority,
                    "count": count,
                    "examples": [item["feedback_text"] for item in feedback_items[-3:]]
                }
        
        return suggestions
```

## 7. Practical Implementation of Reasoning Enhancement

Here's a practical example of implementing reasoning enhancement in an AI agent:

```python
def enhance_reasoning_capability(agent_response, question):
    """Enhance the reasoning capability of an AI agent"""
    # Check if the response contains reasoning
    has_reasoning = "because" in agent_response.lower() or "since" in agent_response.lower()
    
    if not has_reasoning:
        # Prompt for reasoning
        enhanced_prompt = f"""
        Original question: {question}
        Your initial response: {agent_response}
        
        Please improve your response by:
        1. Explicitly stating your reasoning process
        2. Explaining why your conclusion follows from the premises
        3. Considering alternative viewpoints
        4. Addressing potential objections
        
        Enhanced response:
        """
        
        # This would typically call the AI model again with the enhanced prompt
        # For this example, we'll just return the prompt
        return enhanced_prompt
    
    return agent_response
```

## 8. Implementing Continuous Learning

Continuous learning helps AI agents improve over time:

```python
class ContinuousLearningSystem:
    def __init__(self):
        self.learning_database = {
            "successful_patterns": {},
            "error_patterns": {},
            "user_preferences": {}
        }
    
    def record_interaction(self, query, response, success, user_id=None):
        """Record an interaction for learning"""
        # Extract patterns from successful and unsuccessful interactions
        patterns = self._extract_patterns(query)
        
        for pattern in patterns:
            if success:
                if pattern not in self.learning_database["successful_patterns"]:
                    self.learning_database["successful_patterns"][pattern] = 0
                self.learning_database["successful_patterns"][pattern] += 1
            else:
                if pattern not in self.learning_database["error_patterns"]:
                    self.learning_database["error_patterns"][pattern] = 0
                self.learning_database["error_patterns"][pattern] += 1
        
        # Record user preferences if user_id is provided
        if user_id:
            if user_id not in self.learning_database["user_preferences"]:
                self.learning_database["user_preferences"][user_id] = []
            
            self.learning_database["user_preferences"][user_id].append({
                "query": query,
                "response": response,
                "success": success,
                "timestamp": time.time()
            })
    
    def _extract_patterns(self, text):
        """Extract patterns from text for learning"""
        # Simplified implementation
        patterns = []
        
        # Extract n-grams
        words = text.lower().split()
        for n in [1, 2, 3]:
            for i in range(len(words) - n + 1):
                pattern = " ".join(words[i:i+n])
                patterns.append(pattern)
        
        return patterns
    
    def get_improvement_insights(self):
        """Get insights for improvement based on learning data"""
        insights = []
        
        # Find patterns that frequently lead to errors
        error_prone_patterns = {k: v for k, v in self.learning_database["error_patterns"].items() 
                               if v >= 3}
        
        for pattern, count in sorted(error_prone_patterns.items(), key=lambda x: x[1], reverse=True):
            # Check if this pattern also appears in successful interactions
            success_count = self.learning_database["successful_patterns"].get(pattern, 0)
            
            if success_count < count:
                insights.append({
                    "pattern": pattern,
                    "error_count": count,
                    "success_count": success_count,
                    "recommendation": "Improve handling of this pattern"
                })
        
        return insights
```

## Conclusion

Implementing these techniques will significantly enhance your AI agent's capabilities. The code examples provided serve as a starting point for building more sophisticated systems. Remember that improvement is an iterative process - continuously monitor performance, gather feedback, and refine your implementation.

Key takeaways:
1. Implement structured reasoning approaches like chain-of-thought
2. Build robust frameworks for tool selection and chaining
3. Develop self-monitoring and evaluation systems
4. Create mechanisms for knowledge integration and continuous learning
5. Implement feedback systems to learn from user interactions

By systematically implementing these improvements, you can create AI agents that are more capable, reliable, and effective at solving complex problems.

================
File: app.py
================
app = FastAPI()
⋮----
templates = Jinja2Templates(directory="templates")
⋮----
class Task(BaseModel)
⋮----
id: str
prompt: str
created_at: datetime
status: str
steps: list = []
⋮----
def model_dump(self, *args, **kwargs)
⋮----
data = super().model_dump(*args, **kwargs)
⋮----
class TaskManager
⋮----
def __init__(self)
⋮----
def create_task(self, prompt: str) -> Task
⋮----
task_id = str(uuid.uuid4())
task = Task(
⋮----
task = self.tasks[task_id]
⋮----
async def complete_task(self, task_id: str)
⋮----
async def fail_task(self, task_id: str, error: str)
⋮----
task_manager = TaskManager()
⋮----
@app.get("/", response_class=HTMLResponse)
async def index(request: Request)
⋮----
@app.post("/tasks")
async def create_task(prompt: str = Body(..., embed=True))
⋮----
task = task_manager.create_task(prompt)
⋮----
async def run_task(task_id: str, prompt: str)
⋮----
agent = await Manus.create(
⋮----
async def on_think(thought)
⋮----
async def on_tool_execute(tool, input)
⋮----
async def on_action(action)
⋮----
async def on_run(step, result)
⋮----
class SSELogHandler
⋮----
def __init__(self, task_id)
⋮----
async def __call__(self, message)
⋮----
# 提取 - 后面的内容
cleaned_message = re.sub(r"^.*? - ", "", message)
⋮----
event_type = "log"
⋮----
event_type = "think"
⋮----
event_type = "tool"
⋮----
event_type = "act"
⋮----
event_type = "error"
⋮----
event_type = "complete"
⋮----
sse_handler = SSELogHandler(task_id)
⋮----
result = await agent.run(prompt)
⋮----
@app.get("/tasks/{task_id}/events")
async def task_events(task_id: str)
⋮----
async def event_generator()
⋮----
queue = task_manager.queues[task_id]
⋮----
task = task_manager.tasks.get(task_id)
⋮----
status_data = {"type": "status", "status": task.status, "steps": task.steps}
⋮----
event = await queue.get()
formatted_event = dumps(event)
⋮----
status_data = {
⋮----
@app.get("/tasks")
async def get_tasks()
⋮----
sorted_tasks = sorted(
⋮----
@app.get("/tasks/{task_id}")
async def get_task(task_id: str)
⋮----
@app.exception_handler(Exception)
async def generic_exception_handler(request: Request, exc: Exception)

================
File: CODE_OF_CONDUCT.md
================
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, caste, color, religion, or sexual
identity and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people.
* Being respectful of differing opinions, viewpoints, and experiences.
* Giving and gracefully accepting constructive feedback.
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience.
* Focusing on what is best not just for us as individuals, but for the overall
  community.

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or advances of
  any kind.
* Trolling, insulting or derogatory comments, and personal or political attacks.
* Public or private harassment.
* Publishing others' private information, such as a physical or email address,
  without their explicit permission.
* Other conduct which could reasonably be considered inappropriate in a
  professional setting.

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official email address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
mannaandpoem@gmail.com
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series of
actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or permanent
ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within the
community.

### Slack and Discord Etiquettes

These Slack and Discord etiquette guidelines are designed to foster an inclusive, respectful, and productive environment
for all community members. By following these best practices, we ensure effective communication and collaboration while
minimizing disruptions. Let’s work together to build a supportive and welcoming community!

- Communicate respectfully and professionally, avoiding sarcasm or harsh language, and remember that tone can be
  difficult to interpret in text.
- Use threads for specific discussions to keep channels organized and easier to follow.
- Tag others only when their input is critical or urgent, and use @here, @channel or @everyone sparingly to minimize
  disruptions.
- Be patient, as open-source contributors and maintainers often have other commitments and may need time to respond.
- Post questions or discussions in the most relevant
  channel ([discord - #general](https://discord.com/channels/1125308739348594758/1138430348557025341)).
- When asking for help or raising issues, include necessary details like links, screenshots, or clear explanations to
  provide context.
- Keep discussions in public channels whenever possible to allow others to benefit from the conversation, unless the
  matter is sensitive or private.
- Always adhere to [our standards](https://github.com/mannaandpoem/OpenManus/blob/main/CODE_OF_CONDUCT.md#our-standards)
  to ensure a welcoming and collaborative environment.
- If you choose to mute a channel, consider setting up alerts for topics that still interest you to stay engaged. For
  Slack, Go to Settings → Notifications → My Keywords to add specific keywords that will notify you when mentioned. For
  example, if you're here for discussions about LLMs, mute the channel if it’s too busy, but set notifications to alert
  you only when “LLMs” appears in messages. Also for Discord, go to the channel notifications and choose the option that
  best describes your need.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.1, available at
[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].

Community Impact Guidelines were inspired by
[Mozilla's code of conduct enforcement ladder][Mozilla CoC].

For answers to common questions about this code of conduct, see the FAQ at
[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at
[https://www.contributor-covenant.org/translations][translations].

[homepage]: https://www.contributor-covenant.org

[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html

[Mozilla CoC]: https://github.com/mozilla/diversity

[FAQ]: https://www.contributor-covenant.org/faq

[translations]: https://www.contributor-covenant.org/translations

================
File: improving_ai_agent_capabilities.md
================
# Comprehensive Guide to Improving AI Agent Capabilities

This guide outlines key strategies and best practices for enhancing AI agent capabilities, drawing from research by leading organizations like Anthropic and industry experts.

## 1. Enhancing Reasoning Capabilities

### Chain-of-Thought Prompting
- Implement step-by-step reasoning processes that break down complex problems
- Guide the agent through explicit reasoning paths before reaching conclusions
- Use structured formats that encourage methodical thinking

### Tool-Integrated Reasoning
- Develop the ability to identify when external tools are needed
- Create clear decision frameworks for tool selection
- Implement feedback loops to learn from tool usage outcomes

### Agentic Reasoning
- Build capabilities to decompose complex tasks into manageable subtasks
- Implement planning mechanisms that consider multiple solution paths
- Develop self-monitoring systems to evaluate reasoning quality

## 2. Improving Problem-Solving Abilities

### Systematic Approach to Problems
- Implement frameworks for problem identification and classification
- Develop structured approaches to solution generation
- Create evaluation mechanisms for solution quality

### Learning from Experience
- Build systems to record past problem-solving attempts
- Implement mechanisms to analyze successes and failures
- Create knowledge repositories of effective solutions

### Diverse Solution Generation
- Develop capabilities to approach problems from multiple perspectives
- Implement techniques for creative solution generation
- Build evaluation frameworks that consider solution novelty and effectiveness

## 3. Enhancing Knowledge and Information Processing

### Knowledge Integration
- Develop systems to effectively integrate new information with existing knowledge
- Implement verification mechanisms for information accuracy
- Create structured knowledge representations for efficient retrieval

### Information Synthesis
- Build capabilities to combine information from multiple sources
- Develop frameworks for resolving conflicting information
- Implement summarization techniques that preserve critical details

### Continuous Learning
- Create systems for ongoing knowledge acquisition
- Implement mechanisms to identify knowledge gaps
- Develop prioritization frameworks for learning objectives

## 4. Improving Tool Usage and Integration

### Tool Selection Optimization
- Develop sophisticated decision frameworks for choosing appropriate tools
- Implement learning mechanisms to improve tool selection over time
- Create evaluation systems for tool effectiveness

### Tool Chaining
- Build capabilities to combine multiple tools for complex tasks
- Develop planning systems for multi-step tool usage
- Implement error recovery mechanisms for tool chains

### Custom Tool Development
- Create frameworks for identifying needs for new tools
- Implement systems for tool specification and design
- Develop evaluation mechanisms for custom tool effectiveness

## 5. Enhancing Communication and Interaction

### Clear Communication
- Develop capabilities to adjust communication style to audience needs
- Implement frameworks for structuring complex information
- Create mechanisms to verify understanding

### Effective Collaboration
- Build systems for understanding user intentions and goals
- Implement frameworks for aligning agent actions with user objectives
- Develop capabilities for appropriate initiative-taking

### Feedback Integration
- Create systems for soliciting and processing user feedback
- Implement mechanisms to adapt behavior based on feedback
- Develop frameworks for continuous improvement

## 6. Improving Self-Monitoring and Evaluation

### Error Detection
- Build capabilities to identify potential errors in reasoning or outputs
- Implement verification mechanisms for critical decisions
- Create systems for proactive error correction

### Performance Evaluation
- Develop frameworks for assessing agent performance across dimensions
- Implement mechanisms for identifying improvement opportunities
- Create systems for tracking progress over time

### Limitation Awareness
- Build capabilities to recognize agent limitations
- Implement frameworks for communicating limitations to users
- Develop strategies for managing tasks beyond current capabilities

## 7. Technical Implementation Strategies

### Prompt Engineering
- Design prompts that encourage structured reasoning
- Implement techniques like few-shot learning in prompts
- Create prompt libraries for different reasoning tasks

### Fine-Tuning Approaches
- Develop targeted datasets for specific capability enhancement
- Implement progressive fine-tuning strategies
- Create evaluation frameworks for fine-tuning effectiveness

### Architecture Optimization
- Explore architectural modifications for specific capabilities
- Implement modular designs that allow targeted improvements
- Develop benchmarking systems for architectural changes

## 8. Best Practices from Industry Leaders

### Anthropic's Recommendations
- Focus on developing clear reasoning paths before conclusions
- Implement systems that can explain their decision processes
- Create robust evaluation frameworks for agent capabilities

### Research-Backed Approaches
- Prioritize transparency in agent decision-making
- Implement human feedback mechanisms throughout development
- Develop comprehensive testing frameworks for capabilities

### Emerging Techniques
- Explore multi-agent systems for complex problem-solving
- Implement retrieval-augmented generation for knowledge enhancement
- Develop simulation environments for capability testing

## Conclusion

Improving AI agent capabilities requires a multifaceted approach that addresses reasoning, problem-solving, knowledge management, tool usage, communication, and self-evaluation. By implementing the strategies outlined in this guide, developers can create more effective, reliable, and valuable AI agents that better serve user needs.

This guide represents current best practices and should be updated as the field evolves and new research emerges.

================
File: LICENSE
================
MIT License

Copyright (c) 2025 manna_and_poem

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: main.py
================
async def main()
⋮----
"""Main entry point for the OpenManus CLI."""
# Parse command-line arguments
parser = argparse.ArgumentParser(description="OpenManus CLI")
⋮----
args = parser.parse_args()
⋮----
# Create the agent
agent = await Manus.create()
⋮----
# Get user input from command-line argument or prompt
⋮----
prompt = args.prompt
⋮----
prompt = input("Enter your prompt: ")
⋮----
# Process the request
⋮----
# Ignore known MCP SDK errors during shutdown
⋮----
pass  # Silently ignore these errors

================
File: openmanus_repo_map.md
================
# OpenManus Repository Map

## Project Overview

OpenManus is an autonomous AI agent built as a wrapper around foundation models. It operates in a cloud-based virtual computing environment with access to tools like web browsers, shell commands, and code execution. The system's key innovation is using executable Python code as its action mechanism ("CodeAct" approach), allowing it to perform complex operations autonomously. The architecture consists of an iterative agent loop (analyze → plan → execute → observe), with specialized modules for planning, knowledge retrieval, and memory management.

## Directory Structure

```
OpenManus/
├── app/                       # Main application code
│   ├── agent/                 # Agent implementations
│   │   ├── base.py            # Base agent class
│   │   ├── manus.py           # Main Manus agent implementation
│   │   ├── planning.py        # Planning agent implementation
│   │   ├── react.py           # ReAct agent implementation
│   │   ├── swe.py             # Software engineering agent
│   │   └── toolcall.py        # Tool calling functionality
│   ├── flow/                  # Flow management
│   │   ├── base.py            # Base flow class
│   │   ├── flow_factory.py    # Flow factory
│   │   └── planning.py        # Planning flow
│   ├── llm/                   # LLM integration
│   │   ├── cost.py            # Cost tracking
│   │   └── inference.py       # Inference functionality
│   ├── mcp/                   # MCP SDK integration
│   │   ├── client.py          # MCP client
│   │   └── tool.py            # MCP tool integration
│   ├── prompt/                # System prompts
│   │   ├── code_editor.py     # Code editor prompts
│   │   ├── manus.py           # Manus system prompts
│   │   ├── planning.py        # Planning prompts
│   │   ├── swe.py             # Software engineering prompts
│   │   └── toolcall.py        # Tool calling prompts
│   └── tool/                  # Tool implementations
│       ├── ask_human.py       # Human interaction tool
│       ├── base.py            # Base tool class
│       ├── bash.py            # Bash command execution
│       ├── browser_use_tool.py # Browser interaction
│       ├── code_editor.py     # Code editing tool
│       ├── file_saver.py      # File saving tool
│       ├── python_execute.py  # Python execution tool
│       ├── repo_map.py        # Repository mapping tool
│       ├── search/            # Search tools
│       │   ├── baidu_search.py # Baidu search
│       │   ├── base.py        # Base search class
│       │   ├── duckduckgo_search.py # DuckDuckGo search
│       │   └── google_search.py # Google search
│       ├── terminate.py       # Termination tool
│       ├── tool_collection.py # Tool collection management
│       └── web_search.py      # Web search tool
├── config/                    # Configuration files
├── examples/                  # Example use cases
├── logs/                      # Log files
├── openmanus_server/          # Server implementation
│   ├── openmanus_server.py    # Server code
│   └── openmanus_client.py    # Client code
├── static/                    # Static assets for web UI
├── templates/                 # HTML templates for web UI
├── tests/                     # Test suite
├── app.py                     # FastAPI web application
├── main.py                    # CLI entry point
├── requirements.txt           # Python dependencies
├── run_flow.py                # Flow execution script
└── setup.py                   # Package setup
```

## Key Components

### 1. Agent System

The agent system is built around a modular architecture with different agent implementations:

- **Manus Agent (`app/agent/manus.py`)**: The main agent implementation that combines planning and tool usage to solve complex tasks.
- **ToolCall Agent (`app/agent/toolcall.py`)**: Handles tool calling functionality.
- **ReAct Agent (`app/agent/react.py`)**: Implements the ReAct (Reasoning and Acting) paradigm.
- **Planning Agent (`app/agent/planning.py`)**: Focuses on planning and breaking down complex tasks.

### 2. Tool System

OpenManus provides a rich set of tools for the agent to interact with the environment:

- **Code Editor (`app/tool/code_editor.py`)**: Allows editing code files with different formats (whole file, diff, udiff).
- **Python Execute (`app/tool/python_execute.py`)**: Executes Python code.
- **Browser Tool (`app/tool/browser_use_tool.py`)**: Interacts with web browsers.
- **File Saver (`app/tool/file_saver.py`)**: Saves content to files.
- **Repo Map (`app/tool/repo_map.py`)**: Generates repository structure maps.
- **Web Search (`app/tool/web_search.py`)**: Performs web searches.
- **Ask Human (`app/tool/ask_human.py`)**: Requests human input.
- **Terminate (`app/tool/terminate.py`)**: Ends the interaction.

### 3. Prompt System

The system uses carefully crafted prompts to guide the agent's behavior:

- **Manus Prompts (`app/prompt/manus.py`)**: System and next-step prompts for the Manus agent.
- **Code Editor Prompts (`app/prompt/code_editor.py`)**: Prompts for code editing functionality.
- **Tool Call Prompts (`app/prompt/toolcall.py`)**: Prompts for tool calling.
- **Planning Prompts (`app/prompt/planning.py`)**: Prompts for planning tasks.

### 4. Entry Points

- **CLI (`main.py`)**: Command-line interface for interacting with the agent.
- **Web API (`app.py`)**: FastAPI web application for interacting with the agent through a web interface.
- **Server (`openmanus_server/openmanus_server.py`)**: Server implementation for remote access.

## Key Features

1. **CodeAct Approach**: Uses executable Python code as the action mechanism.
2. **Iterative Agent Loop**: Analyze → Plan → Execute → Observe.
3. **Tool Integration**: Rich set of tools for environment interaction.
4. **Multiple Agent Types**: Different agent implementations for different use cases.
5. **Web and CLI Interfaces**: Multiple ways to interact with the system.

## Development Workflow

1. The agent receives a user prompt through either the CLI or web interface.
2. The agent analyzes the prompt and plans a solution.
3. The agent executes the plan using available tools.
4. The agent observes the results and iterates if necessary.
5. The agent returns the final results to the user.

## Configuration

Configuration is handled through files in the `config/` directory, allowing customization of:

- LLM providers and models
- Tool availability and behavior
- Agent parameters (max steps, observation limits, etc.)

================
File: README_ja.md
================
[English](README.md) | [中文](README_zh.md) | [한국어](README_ko.md) | 日本語


[![GitHub stars](https://img.shields.io/github/stars/mannaandpoem/OpenManus?style=social)](https://github.com/mannaandpoem/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)

# 👋 OpenManus

Manusは素晴らしいですが、OpenManusは*招待コード*なしでどんなアイデアも実現できます！🛫

私たちのチームメンバー [@Xinbin Liang](https://github.com/mannaandpoem) と [@Jinyu Xiang](https://github.com/XiangJinyu)（主要開発者）、そして [@Zhaoyang Yu](https://github.com/MoshiQAQ)、[@Jiayi Zhang](https://github.com/didiforgithub)、[@Sirui Hong](https://github.com/stellaHSR) は [@MetaGPT](https://github.com/geekan/MetaGPT) から来ました。プロトタイプは3時間以内に立ち上げられ、継続的に開発を進めています！

これはシンプルな実装ですので、どんな提案、貢献、フィードバックも歓迎します！

OpenManusで自分だけのエージェントを楽しみましょう！

また、UIUCとOpenManusの研究者が共同開発した[OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)をご紹介できることを嬉しく思います。これは強化学習（RL）ベース（GRPOなど）のLLMエージェントチューニング手法に特化したオープンソースプロジェクトです。

## プロジェクトデモ

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## インストール方法

インストール方法は2つ提供しています。方法2（uvを使用）は、より高速なインストールと優れた依存関係管理のため推奨されています。

### 方法1：condaを使用

1. 新しいconda環境を作成します：

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. リポジトリをクローンします：

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 依存関係をインストールします：

```bash
pip install -r requirements.txt
```

### 方法2：uvを使用（推奨）

1. uv（高速なPythonパッケージインストーラーと管理機能）をインストールします：

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. リポジトリをクローンします：

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 新しい仮想環境を作成してアクティベートします：

```bash
uv venv
source .venv/bin/activate  # Unix/macOSの場合
# Windowsの場合：
# .venv\Scripts\activate
```

4. 依存関係をインストールします：

```bash
uv pip install -r requirements.txt
```

## 設定

OpenManusを使用するには、LLM APIの設定が必要です。以下の手順に従って設定してください：

1. `config`ディレクトリに`config.toml`ファイルを作成します（サンプルからコピーできます）：

```bash
cp config/config.example.toml config/config.toml
```

2. `config/config.toml`を編集してAPIキーを追加し、設定をカスタマイズします：

```toml
# グローバルLLM設定
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 実際のAPIキーに置き換えてください
max_tokens = 4096
temperature = 0.0

# 特定のLLMモデル用のオプション設定
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 実際のAPIキーに置き換えてください
```

## クイックスタート

OpenManusを実行する一行コマンド：

```bash
python main.py
```

その後、ターミナルからプロンプトを入力してください！

開発中バージョンを試すには、以下を実行します：

```bash
python run_flow.py
```

## 貢献方法

我々は建設的な意見や有益な貢献を歓迎します！issueを作成するか、プルリクエストを提出してください。

または @mannaandpoem に📧メールでご連絡ください：mannaandpoem@gmail.com

**注意**: プルリクエストを送信する前に、pre-commitツールを使用して変更を確認してください。`pre-commit run --all-files`を実行してチェックを実行します。

## コミュニティグループ
Feishuのネットワーキンググループに参加して、他の開発者と経験を共有しましょう！

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus 交流群" width="300" />
</div>

## スター履歴

[![Star History Chart](https://api.star-history.com/svg?repos=mannaandpoem/OpenManus&type=Date)](https://star-history.com/#mannaandpoem/OpenManus&Date)

## 謝辞

このプロジェクトの基本的なサポートを提供してくれた[anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
と[browser-use](https://github.com/browser-use/browser-use)に感謝します！

さらに、[AAAJ](https://github.com/metauto-ai/agent-as-a-judge)、[MetaGPT](https://github.com/geekan/MetaGPT)、[OpenHands](https://github.com/All-Hands-AI/OpenHands)、[SWE-agent](https://github.com/SWE-agent/SWE-agent)にも感謝します。

OpenManusはMetaGPTのコントリビューターによって構築されました。このエージェントコミュニティに大きな感謝を！

## 引用
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mannaandpoem/OpenManus}},
}

================
File: README_ko.md
================
[English](README.md) | [中文](README_zh.md) | 한국어 | [日本語](README_ja.md)


[![GitHub stars](https://img.shields.io/github/stars/mannaandpoem/OpenManus?style=social)](https://github.com/mannaandpoem/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)

# 👋 OpenManus

Manus는 놀라운 도구지만, OpenManus는 *초대 코드* 없이도 모든 아이디어를 실현할 수 있습니다! 🛫

우리 팀의 멤버인 [@Xinbin Liang](https://github.com/mannaandpoem)와 [@Jinyu Xiang](https://github.com/XiangJinyu) (핵심 작성자), 그리고 [@Zhaoyang Yu](https://github.com/MoshiQAQ), [@Jiayi Zhang](https://github.com/didiforgithub), [@Sirui Hong](https://github.com/stellaHSR)이 함께 했습니다. 우리는 [@MetaGPT](https://github.com/geekan/MetaGPT)로부터 왔습니다. 프로토타입은 단 3시간 만에 출시되었으며, 계속해서 발전하고 있습니다!

이 프로젝트는 간단한 구현에서 시작되었으며, 여러분의 제안, 기여 및 피드백을 환영합니다!

OpenManus를 통해 여러분만의 에이전트를 즐겨보세요!

또한 [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)을 소개하게 되어 기쁩니다. OpenManus와 UIUC 연구자들이 공동 개발한 이 오픈소스 프로젝트는 LLM 에이전트에 대해 강화 학습(RL) 기반 (예: GRPO) 튜닝 방법을 제공합니다.

## 프로젝트 데모

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## 설치 방법

두 가지 설치 방법을 제공합니다. **방법 2 (uv 사용)** 이 더 빠른 설치와 효율적인 종속성 관리를 위해 권장됩니다.

### 방법 1: conda 사용

1. 새로운 conda 환경을 생성합니다:

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. 저장소를 클론합니다:

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 종속성을 설치합니다:

```bash
pip install -r requirements.txt
```

### 방법 2: uv 사용 (권장)

1. uv를 설치합니다. (빠른 Python 패키지 설치 및 종속성 관리 도구):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. 저장소를 클론합니다:

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 새로운 가상 환경을 생성하고 활성화합니다:

```bash
uv venv
source .venv/bin/activate  # Unix/macOS의 경우
# Windows의 경우:
# .venv\Scripts\activate
```

4. 종속성을 설치합니다:

```bash
uv pip install -r requirements.txt
```

## 설정 방법

OpenManus를 사용하려면 사용하는 LLM API에 대한 설정이 필요합니다. 아래 단계를 따라 설정을 완료하세요:

1. `config` 디렉토리에 `config.toml` 파일을 생성하세요 (예제 파일을 복사하여 사용할 수 있습니다):

```bash
cp config/config.example.toml config/config.toml
```

2. `config/config.toml` 파일을 편집하여 API 키를 추가하고 설정을 커스터마이징하세요:

```toml
# 전역 LLM 설정
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 실제 API 키로 변경하세요
max_tokens = 4096
temperature = 0.0

# 특정 LLM 모델에 대한 선택적 설정
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 실제 API 키로 변경하세요
```

## 빠른 시작

OpenManus를 실행하는 한 줄 명령어:

```bash
python main.py
```

이후 터미널에서 아이디어를 작성하세요!

unstable 버전을 실행하려면 아래 명령어를 사용할 수도 있습니다:

```bash
python run_flow.py
```

## 기여 방법

모든 친절한 제안과 유용한 기여를 환영합니다! 이슈를 생성하거나 풀 리퀘스트를 제출해 주세요.

또는 📧 메일로 연락주세요. @mannaandpoem : mannaandpoem@gmail.com

**참고**: pull request를 제출하기 전에 pre-commit 도구를 사용하여 변경 사항을 확인하십시오. `pre-commit run --all-files`를 실행하여 검사를 실행합니다.

## 커뮤니티 그룹
Feishu 네트워킹 그룹에 참여하여 다른 개발자들과 경험을 공유하세요!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus 交流群" width="300" />
</div>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mannaandpoem/OpenManus&type=Date)](https://star-history.com/#mannaandpoem/OpenManus&Date)

## 감사의 글

이 프로젝트에 기본적인 지원을 제공해 주신 [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)와
[browser-use](https://github.com/browser-use/browser-use)에게 감사드립니다!

또한, [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands), [SWE-agent](https://github.com/SWE-agent/SWE-agent)에 깊은 감사를 드립니다.

OpenManus는 MetaGPT 기여자들에 의해 개발되었습니다. 이 에이전트 커뮤니티에 깊은 감사를 전합니다!

## 인용
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mannaandpoem/OpenManus}},
}
```

================
File: README_zh.md
================
[English](README.md) | 中文 | [한국어](README_ko.md) | [日本語](README_ja.md)



[![GitHub stars](https://img.shields.io/github/stars/mannaandpoem/OpenManus?style=social)](https://github.com/mannaandpoem/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)

# 👋 OpenManus

Manus 非常棒，但 OpenManus 无需邀请码即可实现任何创意 🛫！

我们的团队成员 [@Xinbin Liang](https://github.com/mannaandpoem) 和 [@Jinyu Xiang](https://github.com/XiangJinyu)（核心作者），以及 [@Zhaoyang Yu](https://github.com/MoshiQAQ)、[@Jiayi Zhang](https://github.com/didiforgithub) 和 [@Sirui Hong](https://github.com/stellaHSR)，来自 [@MetaGPT](https://github.com/geekan/MetaGPT)团队。我们在 3
小时内完成了开发并持续迭代中！

这是一个简洁的实现方案，欢迎任何建议、贡献和反馈！

用 OpenManus 开启你的智能体之旅吧！

我们也非常高兴地向大家介绍 [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)，这是一个专注于基于强化学习（RL，例如 GRPO）的方法来优化大语言模型（LLM）智能体的开源项目，由来自UIUC 和 OpenManus 的研究人员合作开发。

## 项目演示

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## 安装指南

我们提供两种安装方式。推荐使用方式二（uv），因为它能提供更快的安装速度和更好的依赖管理。

### 方式一：使用 conda

1. 创建新的 conda 环境：

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. 克隆仓库：

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 安装依赖：

```bash
pip install -r requirements.txt
```

### 方式二：使用 uv（推荐）

1. 安装 uv（一个快速的 Python 包管理器）：

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. 克隆仓库：

```bash
git clone https://github.com/mannaandpoem/OpenManus.git
cd OpenManus
```

3. 创建并激活虚拟环境：

```bash
uv venv
source .venv/bin/activate  # Unix/macOS 系统
# Windows 系统使用：
# .venv\Scripts\activate
```

4. 安装依赖：

```bash
uv pip install -r requirements.txt
```

## 配置说明

OpenManus 需要配置使用的 LLM API，请按以下步骤设置：

1. 在 `config` 目录创建 `config.toml` 文件（可从示例复制）：

```bash
cp config/config.example.toml config/config.toml
```

2. 编辑 `config/config.toml` 添加 API 密钥和自定义设置：

```toml
# 全局 LLM 配置
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 替换为真实 API 密钥
max_tokens = 4096
temperature = 0.0

# 可选特定 LLM 模型配置
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # 替换为真实 API 密钥
```

## 快速启动

一行命令运行 OpenManus：

```bash
python main.py
```

然后通过终端输入你的创意！

如需体验不稳定的开发版本，可运行：

```bash
python run_flow.py
```

## 贡献指南

我们欢迎任何友好的建议和有价值的贡献！可以直接创建 issue 或提交 pull request。

或通过 📧 邮件联系 @mannaandpoem：mannaandpoem@gmail.com

**注意**: 在提交 pull request 之前，请使用 pre-commit 工具检查您的更改。运行 `pre-commit run --all-files` 来执行检查。

## 交流群

加入我们的飞书交流群，与其他开发者分享经验！

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus 交流群" width="300" />
</div>

## Star 数量

[![Star History Chart](https://api.star-history.com/svg?repos=mannaandpoem/OpenManus&type=Date)](https://star-history.com/#mannaandpoem/OpenManus&Date)

## 致谢

特别感谢 [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
和 [browser-use](https://github.com/browser-use/browser-use) 为本项目提供的基础支持！

此外，我们感谢 [AAAJ](https://github.com/metauto-ai/agent-as-a-judge)，[MetaGPT](https://github.com/geekan/MetaGPT)，[OpenHands](https://github.com/All-Hands-AI/OpenHands) 和 [SWE-agent](https://github.com/SWE-agent/SWE-agent).

OpenManus 由 MetaGPT 社区的贡献者共同构建，感谢这个充满活力的智能体开发者社区！

## 引用我们

```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mannaandpoem/OpenManus}},
}
```

================
File: README.md
================
English | [中文](README_zh.md) | [한국어](README_ko.md) | [日本語](README_ja.md)

[![GitHub stars](https://img.shields.io/github/stars/mannaandpoem/OpenManus?style=social)](https://github.com/mannaandpoem/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)

# 👋 OpenManus

OpenManus is an autonomous AI agent that can perform complex tasks by interacting with your computer. It uses large language models (LLMs) to understand your instructions and execute them using tools like web browsers, shell commands, and code editors.

## Quick Start

Want to see OpenManus in action? Here's a simple example that creates a text file:

1.  **Installation:**

    We provide two installation methods. Method 2 (using uv) is recommended for faster installation and better dependency management.

    ### Method 1: Using conda

    1.  Create a new conda environment:

        ```bash
        conda create -n open_manus python=3.12
        conda activate open_manus
        ```

    2.  Clone the repository:

        ```bash
        git clone https://github.com/mannaandpoem/OpenManus.git
        cd OpenManus
        ```

    3.  Install dependencies:

        ```bash
        pip install -r requirements.txt
        ```

    ### Method 2: Using uv (Recommended)

    1.  Install uv (A fast Python package installer and resolver):

        ```bash
        curl -LsSf https://astral.sh/uv/install.sh | sh
        ```

    2.  Clone the repository:

        ```bash
        git clone https://github.com/mannaandpoem/OpenManus.git
        cd OpenManus
        ```

    3.  Create a new virtual environment and activate it:

        ```bash
        uv venv
        source .venv/bin/activate  # On Unix/macOS
        # Or on Windows:
        # .venv\Scripts\activate
        ```

    4.  Install dependencies:

        ```bash
        uv pip install -r requirements.txt
        ```

2.  **Configuration:**

    *   Create a `config.toml` file in the `config` directory:

        ```bash
        cp config/config.example.toml config/config.toml
        ```

    *   Edit `config/config.toml` and add your OpenAI API key:

        ```toml
        [llm]
        model = "gpt-4o"
        base_url = "https://api.openai.com/v1"
        api_key = "sk-..."  # Replace with your actual API key
        max_tokens = 4096
        temperature = 0.0
        ```
3. **Run OpenManus:**
   ```bash
    python main.py
   ```
4. **Input the following instruction in the terminal:**
   ```
    Create a file named 'hello.txt' in the workspace directory and write 'Hello, OpenManus!' into it.
   ```

OpenManus will create the file and write the text into it. You can find the file in the `workspace` directory.

## Key Features

- **Versatile File Operations**: The enhanced CodeEditor tool handles all file operations:
  - Create, modify, or save any type of file (code, text, data, etc.)
  - Support for both write and append modes
  - Automatic directory creation

- **Advanced Code Editing**: OpenManus features powerful code editing capabilities with multiple formats:
  - **Diff Format**: Make targeted changes to specific parts of files using SEARCH/REPLACE blocks
  - **Whole Format**: Create new files or completely rewrite existing ones
  - **Unified Diff Format**: Apply complex changes across multiple parts of a file

- **Repository Mapping**: Generate comprehensive maps of code repositories to understand structure and relationships

- **Web Browsing**: Interact with websites for information gathering and testing

- **Web Search**: Perform web searches using multiple search engines (Google, Baidu, DuckDuckGo)

- **Python Execution**: Run Python code to process data and automate tasks

- **Planning System**: Create and manage structured plans with step tracking and progress monitoring

- **MCP Integration**: Connect to Model Context Protocol (MCP) servers to extend functionality:
  - Register custom tools from MCP servers
  - Execute tools as part of the agent's workflow
  - Access external APIs and services

- **OpenManus Server**: A dedicated MCP server that exposes OpenManus tools as standardized APIs:
  - Browser automation
  - Google search
  - Python code execution
  - File saving
  - Termination control

- **Multiple Agent Types**:
  - **Manus**: A versatile general-purpose agent with comprehensive tools
  - **PlanningAgent**: An agent focused on creating and managing plans
  - **SWEAgent**: An autonomous AI programmer for software engineering tasks

## Use Cases
- **Automate repetitive tasks:**  Automate file manipulations, data processing, and other tasks.
- **Rapid prototyping:** Quickly create and test code snippets or scripts.
- **Web scraping and data extraction:** Gather information from websites.
- **Code refactoring and improvement:**  Make targeted changes to existing code.
- **Learning and experimentation:** Explore new libraries and APIs.

It's a simple implementation, so we welcome any suggestions, contributions, and feedback!

Enjoy your own agent with OpenManus!

We're also excited to introduce [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL), an open-source project dedicated to reinforcement learning (RL)- based (such as GRPO) tuning methods for LLM agents, developed collaboratively by researchers from UIUC and OpenManus.

## Project Demo

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

### Using OpenManus Server

To use the OpenManus server with Claude for Desktop:

1. Install MCP dependencies:

```bash
uv pip install -r openmanus_server/mcp_requirements.txt
```

2. Configure Claude for Desktop to use the OpenManus server:

```json
{
    "mcpServers": {
        "openmanus": {
            "command": "/path/to/uv",
            "args": [
                "--directory",
                "/path/to/OpenManus/openmanus_server",
                "run",
                "openmanus_server.py"
            ]
        }
    }
}
```

3. Restart Claude for Desktop and look for the hammer icon to access the OpenManus tools.

## How to contribute

We welcome any friendly suggestions and helpful contributions! Just create issues or submit pull requests.

Or contact @mannaandpoem via 📧email: mannaandpoem@gmail.com

**Note**: Before submitting a pull request, please use the pre-commit tool to check your changes. Run `pre-commit run --all-files` to execute the checks.

## Community Group
Join our networking group on Feishu and share your experience with other developers!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus 交流群" width="300" />
</div>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mannaandpoem/OpenManus&type=Date)](https://star-history.com/#mannaandpoem/OpenManus&Date)

## Acknowledgement

Thanks to [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
and [browser-use](https://github.com/browser-use/browser-use) for providing basic support for this project!

Additionally, we are grateful to [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands) and [SWE-agent](https://github.com/SWE-agent/SWE-agent).

OpenManus is built by contributors from MetaGPT. Huge thanks to this agent community!

## Cite
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mannaandpoem/OpenManus}},
}

================
File: requirements.txt
================
pydantic~=2.10.4
openai>=1.61.0
tenacity~=9.0.0
pyyaml~=6.0.2
loguru~=0.7.3
numpy
datasets~=3.2.0
fastapi~=0.115.11

html2text~=2024.2.26
gymnasium~=1.0.0
pillow~=10.4.0
browsergym~=0.13.3
uvicorn~=0.34.0
unidiff~=0.7.5
browser-use~=0.1.40
googlesearch-python~=1.3.0
baidusearch~=1.0.3
duckduckgo_search~=7.5.1

aiofiles~=24.1.0
pydantic_core~=2.27.2
colorama~=0.4.6
playwright~=1.49.1
litellm~=1.63.6

# MCP SDK
mcp
aider-install

================
File: run_flow.py
================
async def run_flow()
⋮----
# Create and initialize all available agents
manus_agent = await Manus.create()
swe_agent = await SWEAgent().create()
⋮----
# Create a dictionary of all agents
all_agents = {
⋮----
# Use the selected agent for the flow
agents = all_agents
⋮----
prompt = input("Enter your prompt: ")
⋮----
flow = FlowFactory.create_flow(
⋮----
start_time = time.time()
result = await asyncio.wait_for(
⋮----
timeout=3600,  # 60 minute timeout for the entire execution
⋮----
elapsed_time = time.time() - start_time
⋮----
# Ignore known MCP SDK errors during shutdown
⋮----
pass  # Silently ignore these errors

================
File: run_tests.py
================
#!/usr/bin/env python3
"""
Test runner for OpenManus.

This script runs the tests for the OpenManus project.
"""
⋮----
def run_tests(test_path=None, verbose=False)
⋮----
"""
    Run the tests.
    
    Args:
        test_path: Path to the test file or directory to run
        verbose: Whether to run tests in verbose mode
    """
⋮----
# Convert path to module format if it's a file path
⋮----
# Remove .py extension if present
⋮----
test_path = test_path[:-3]
# Replace / with . to convert to module format
test_path = test_path.replace('/', '.')
⋮----
# Run the specified tests
suite = unittest.defaultTestLoader.loadTestsFromName(test_path)
⋮----
# Run all tests
suite = unittest.defaultTestLoader.discover('tests')
⋮----
# Run the tests
runner = unittest.TextTestRunner(verbosity=2 if verbose else 1)
result = runner.run(suite)
⋮----
# Return exit code based on test result
⋮----
parser = argparse.ArgumentParser(description="Run OpenManus tests")
⋮----
args = parser.parse_args()

================
File: setup.py
================
long_description = fh.read()



================================================================
End of Codebase
================================================================
